package testutil

import (
	"context"
	"fmt"
	"os"
	"strings"
	"testing"
	"time"

	bifrost "github.com/maximhq/bifrost/core"
	"github.com/maximhq/bifrost/core/schemas"
)

// RunChatCompletionStreamTest executes the chat completion stream test scenario
func RunChatCompletionStreamTest(t *testing.T, client *bifrost.Bifrost, ctx context.Context, testConfig ComprehensiveTestConfig) {
	if !testConfig.Scenarios.CompletionStream {
		t.Logf("Chat completion stream not supported for provider %s", testConfig.Provider)
		return
	}

	t.Run("ChatCompletionStream", func(t *testing.T) {
		if os.Getenv("SKIP_PARALLEL_TESTS") != "true" {
			t.Parallel()
		}

		messages := []schemas.ChatMessage{
			CreateBasicChatMessage("Tell me a short story about a robot learning to paint the city which has the eiffel tower. Keep it under 200 words and include the city's name."),
		}

		request := &schemas.BifrostChatRequest{
			Provider: testConfig.Provider,
			Model:    testConfig.ChatModel,
			Input:    messages,
			Params: &schemas.ChatParameters{
				MaxCompletionTokens: bifrost.Ptr(150),
			},
			Fallbacks: testConfig.Fallbacks,
		}

		// Use retry framework for stream requests
		retryConfig := StreamingRetryConfig()
		retryContext := TestRetryContext{
			ScenarioName: "ChatCompletionStream",
			ExpectedBehavior: map[string]interface{}{
				"should_stream_content": true,
				"should_tell_story":     true,
				"topic":                 "robot painting",
			},
			TestMetadata: map[string]interface{}{
				"provider": testConfig.Provider,
				"model":    testConfig.ChatModel,
			},
		}

		// Use proper streaming retry wrapper for the stream request
		responseChannel, err := WithStreamRetry(t, retryConfig, retryContext, func() (chan *schemas.BifrostStream, *schemas.BifrostError) {
			return client.ChatCompletionStreamRequest(ctx, request)
		})

		// Enhanced error handling
		RequireNoError(t, err, "Chat completion stream request failed")
		if responseChannel == nil {
			t.Fatal("Response channel should not be nil")
		}

		var fullContent strings.Builder
		var responseCount int
		var lastResponse *schemas.BifrostStream

		// Create a timeout context for the stream reading
		streamCtx, cancel := context.WithTimeout(ctx, 30*time.Second)
		defer cancel()

		t.Logf("üì° Starting to read streaming response...")

		// Read streaming responses
		for {
			select {
			case response, ok := <-responseChannel:
				if !ok {
					// Channel closed, streaming completed
					t.Logf("‚úÖ Streaming completed. Total chunks received: %d", responseCount)
					goto streamComplete
				}

				if response == nil {
					t.Fatal("Streaming response should not be nil")
				}
				lastResponse = DeepCopyBifrostStream(response)

				// Basic validation of streaming response structure
				if response.BifrostChatResponse != nil {
					if response.BifrostChatResponse.ExtraFields.Provider != testConfig.Provider {
						t.Logf("‚ö†Ô∏è Warning: Provider mismatch - expected %s, got %s", testConfig.Provider, response.BifrostChatResponse.ExtraFields.Provider)
					}
					if response.BifrostChatResponse.ID == "" {
						t.Logf("‚ö†Ô∏è Warning: Response ID is empty")
					}

					// Log latency for each chunk (can be 0 for inter-chunks)
					t.Logf("üìä Chunk %d latency: %d ms", responseCount+1, response.BifrostChatResponse.ExtraFields.Latency)

					// Process each choice in the response
					for _, choice := range response.BifrostChatResponse.Choices {
						// Validate that this is a stream response
						if choice.ChatStreamResponseChoice == nil {
							t.Logf("‚ö†Ô∏è Warning: Stream response choice is nil for choice %d", choice.Index)
							continue
						}
						if choice.ChatNonStreamResponseChoice != nil {
							t.Logf("‚ö†Ô∏è Warning: Non-stream response choice should be nil in streaming response")
						}

						// Get content from delta
						if choice.ChatStreamResponseChoice != nil && choice.ChatStreamResponseChoice.Delta != nil {
							delta := choice.ChatStreamResponseChoice.Delta
							if delta.Content != nil {
								fullContent.WriteString(*delta.Content)
							}

							// Log role if present (usually in first chunk)
							if delta.Role != nil {
								t.Logf("ü§ñ Role: %s", *delta.Role)
							}

							// Check finish reason if present
							if choice.FinishReason != nil {
								t.Logf("üèÅ Finish reason: %s", *choice.FinishReason)
							}
						}
					}
				}

				responseCount++

				// Safety check to prevent infinite loops in case of issues
				if responseCount > 500 {
					t.Fatal("Received too many streaming chunks, something might be wrong")
				}

			case <-streamCtx.Done():
				t.Fatal("Timeout waiting for streaming response")
			}
		}

	streamComplete:
		// Validate final streaming response
		finalContent := strings.TrimSpace(fullContent.String())

		// Create a consolidated response for validation
		consolidatedResponse := &schemas.BifrostChatResponse{
			Choices: []schemas.BifrostResponseChoice{
				{
					Index: 0,
					ChatNonStreamResponseChoice: &schemas.ChatNonStreamResponseChoice{
						Message: &schemas.ChatMessage{
							Role: schemas.ChatMessageRoleAssistant,
							Content: &schemas.ChatMessageContent{
								ContentStr: &finalContent,
							},
						},
					},
				},
			},
			ExtraFields: schemas.BifrostResponseExtraFields{
				Provider: testConfig.Provider,
			},
		}

		// Copy usage and other metadata from last response if available
		if lastResponse != nil && lastResponse.BifrostChatResponse != nil {
			consolidatedResponse.Usage = lastResponse.BifrostChatResponse.Usage
			consolidatedResponse.Model = lastResponse.BifrostChatResponse.Model
			consolidatedResponse.ID = lastResponse.BifrostChatResponse.ID
			consolidatedResponse.Created = lastResponse.BifrostChatResponse.Created

			// Copy finish reason from last choice if available
			if len(lastResponse.BifrostChatResponse.Choices) > 0 && lastResponse.BifrostChatResponse.Choices[0].FinishReason != nil {
				consolidatedResponse.Choices[0].FinishReason = lastResponse.BifrostChatResponse.Choices[0].FinishReason
			}
			consolidatedResponse.ExtraFields.Latency = lastResponse.BifrostChatResponse.ExtraFields.Latency
		}

		// Enhanced validation expectations for streaming
		expectations := GetExpectationsForScenario("ChatCompletionStream", testConfig, map[string]interface{}{})
		expectations = ModifyExpectationsForProvider(expectations, testConfig.Provider)
		expectations.ShouldContainAnyOf = append(expectations.ShouldContainAnyOf, []string{"paris"}...) // Should include story elements                                                         // Reasonable upper bound

		// Validate the consolidated streaming response
		validationResult := ValidateChatResponse(t, consolidatedResponse, nil, expectations, "ChatCompletionStream")

		// Basic streaming validation
		if responseCount == 0 {
			t.Fatal("Should receive at least one streaming response")
		}

		if finalContent == "" {
			t.Fatal("Final content should not be empty")
		}

		if len(finalContent) < 10 {
			t.Fatal("Final content should be substantial")
		}

		if !validationResult.Passed {
			t.Fatalf("‚ùå Streaming validation failed: %v", validationResult.Errors)
		}

		t.Logf("üìä Streaming metrics: %d chunks, %d chars", responseCount, len(finalContent))

		t.Logf("‚úÖ Streaming test completed successfully")
		t.Logf("üìù Final content (%d chars)", len(finalContent))
	})

	// Test streaming with tool calls if supported
	if testConfig.Scenarios.ToolCalls {
		t.Run("ChatCompletionStreamWithTools", func(t *testing.T) {
			if os.Getenv("SKIP_PARALLEL_TESTS") != "true" {
				t.Parallel()
			}

			messages := []schemas.ChatMessage{
				CreateBasicChatMessage("What's the weather like in San Francisco in celsius? Please use the get_weather function."),
			}

			tool := GetSampleChatTool(SampleToolTypeWeather)

			request := &schemas.BifrostChatRequest{
				Provider: testConfig.Provider,
				Model:    testConfig.ChatModel,
				Input:    messages,
				Params: &schemas.ChatParameters{
					MaxCompletionTokens: bifrost.Ptr(150),
					Tools:               []schemas.ChatTool{*tool},
				},
				Fallbacks: testConfig.Fallbacks,
			}

			// Use retry framework for stream requests with tools
			retryConfig := StreamingRetryConfig()
			retryContext := TestRetryContext{
				ScenarioName: "ChatCompletionStreamWithTools",
				ExpectedBehavior: map[string]interface{}{
					"should_stream_content":  true,
					"should_have_tool_calls": true,
					"tool_name":              "get_weather",
				},
				TestMetadata: map[string]interface{}{
					"provider": testConfig.Provider,
					"model":    testConfig.ChatModel,
					"tools":    true,
				},
			}

			// Use validation retry wrapper that includes stream reading and validation
			validationResult := WithChatStreamValidationRetry(
				t,
				retryConfig,
				retryContext,
				func() (chan *schemas.BifrostStream, *schemas.BifrostError) {
					return client.ChatCompletionStreamRequest(ctx, request)
				},
				func(responseChannel chan *schemas.BifrostStream) ChatStreamValidationResult {
					var toolCallDetected bool
					var responseCount int
					var streamErrors []string

					streamCtx, cancel := context.WithTimeout(ctx, 30*time.Second)
					defer cancel()

					t.Logf("üîß Testing streaming with tool calls...")

					for {
						select {
						case response, ok := <-responseChannel:
							if !ok {
								goto toolStreamComplete
							}

							if response == nil || response.BifrostChatResponse == nil {
								streamErrors = append(streamErrors, "‚ùå Streaming response should not be nil")
								continue
							}
							responseCount++

							if response.BifrostChatResponse.Choices != nil {
								for _, choice := range response.BifrostChatResponse.Choices {
									if choice.ChatStreamResponseChoice != nil && choice.ChatStreamResponseChoice.Delta != nil {
										delta := choice.ChatStreamResponseChoice.Delta

										// Check for tool calls in delta
										if len(delta.ToolCalls) > 0 {
											toolCallDetected = true
											t.Logf("üîß Tool call detected in streaming response")

											for _, toolCall := range delta.ToolCalls {
												if toolCall.Function.Name != nil {
													t.Logf("üîß Tool: %s", *toolCall.Function.Name)
													if toolCall.Function.Arguments != "" {
														t.Logf("üîß Args: %s", toolCall.Function.Arguments)
													}
												}
											}
										}
									}
								}
							}

							if responseCount > 100 {
								goto toolStreamComplete
							}

						case <-streamCtx.Done():
							streamErrors = append(streamErrors, "‚ùå Timeout waiting for streaming response with tools")
							goto toolStreamComplete
						}
					}

				toolStreamComplete:
					var errors []string
					if responseCount == 0 {
						errors = append(errors, "‚ùå Should receive at least one streaming response")
					}
					if !toolCallDetected {
						errors = append(errors, fmt.Sprintf("‚ùå Should detect tool calls in streaming response (received %d chunks but no tool calls)", responseCount))
					}
					if len(streamErrors) > 0 {
						errors = append(errors, streamErrors...)
					}

					return ChatStreamValidationResult{
						Passed:           len(errors) == 0,
						Errors:           errors,
						ReceivedData:     responseCount > 0,
						StreamErrors:     streamErrors,
						ToolCallDetected: toolCallDetected,
						ResponseCount:    responseCount,
					}
				},
			)

			// Check validation result
			if !validationResult.Passed {
				allErrors := append(validationResult.Errors, validationResult.StreamErrors...)
				t.Fatalf("‚ùå Chat completion stream with tools validation failed after retries: %s", strings.Join(allErrors, "; "))
			}

			if validationResult.ResponseCount == 0 {
				t.Fatalf("‚ùå Should receive at least one streaming response")
			}
			if !validationResult.ToolCallDetected {
				t.Fatalf("‚ùå Should detect tool calls in streaming response (received %d chunks but no tool calls)", validationResult.ResponseCount)
			}
			t.Logf("‚úÖ Streaming with tools test completed successfully")
		})
	}
}
