// Package gemini provides types and structures for interacting with Google's Gemini API.
package gemini

import (
	"encoding/base64"
	"encoding/json"
	"fmt"
	"reflect"
	"strconv"
	"strings"
	"time"

	"github.com/bytedance/sonic"
	"github.com/maximhq/bifrost/core/schemas"
)

const MinReasoningMaxTokens = 1         // Minimum max tokens for reasoning - used for estimation of effort level
const DefaultCompletionMaxTokens = 8192 // Default max output tokens for Gemini - used for relative reasoning max token calculation
const DefaultReasoningMinBudget = 1024  // Default minimum reasoning budget for Gemini
const DynamicReasoningBudget = -1       // Special value for dynamic reasoning budget in Gemini

type Role string

const (
	RoleUser  = "user"
	RoleModel = "model"
)

// FinishReason represents the reason why the model stopped generating tokens.
// If empty, the model has not stopped generating the tokens.
type FinishReason string

const (
	// The finish reason is unspecified.
	FinishReasonUnspecified FinishReason = "FINISH_REASON_UNSPECIFIED"
	// Token generation reached a natural stopping point or a configured stop sequence.
	FinishReasonStop FinishReason = "STOP"
	// Token generation reached the configured maximum output tokens.
	FinishReasonMaxTokens FinishReason = "MAX_TOKENS"
	// Token generation stopped because the content potentially contains safety violations.
	// NOTE: When streaming, [content][] is empty if content filters blocks the output.
	FinishReasonSafety FinishReason = "SAFETY"
	// The token generation stopped because of potential recitation.
	FinishReasonRecitation FinishReason = "RECITATION"
	// The token generation stopped because of using an unsupported language.
	FinishReasonLanguage FinishReason = "LANGUAGE"
	// All other reasons that stopped the token generation.
	FinishReasonOther FinishReason = "OTHER"
	// Token generation stopped because the content contains forbidden terms.
	FinishReasonBlocklist FinishReason = "BLOCKLIST"
	// Token generation stopped for potentially containing prohibited content.
	FinishReasonProhibitedContent FinishReason = "PROHIBITED_CONTENT"
	// Token generation stopped because the content potentially contains Sensitive Personally
	// Identifiable Information (SPII).
	FinishReasonSPII FinishReason = "SPII"
	// The function call generated by the model is invalid.
	FinishReasonMalformedFunctionCall FinishReason = "MALFORMED_FUNCTION_CALL"
	// Token generation stopped because generated images have safety violations.
	FinishReasonImageSafety FinishReason = "IMAGE_SAFETY"
	// The tool call generated by the model is invalid.
	FinishReasonUnexpectedToolCall FinishReason = "UNEXPECTED_TOOL_CALL"
)

type GeminiGenerationRequest struct {
	Model             string                   `json:"model,omitempty"`    // Model field for explicit model specification
	Contents          []Content                `json:"contents,omitempty"` // For chat completion requests
	Requests          []GeminiEmbeddingRequest `json:"requests,omitempty"` // For batch embedding requests
	SystemInstruction *Content                 `json:"systemInstruction,omitempty"`
	GenerationConfig  GenerationConfig         `json:"generationConfig,omitempty"`
	SafetySettings    []SafetySetting          `json:"safetySettings,omitempty"`
	Tools             []Tool                   `json:"tools,omitempty"`
	ToolConfig        ToolConfig               `json:"toolConfig,omitempty"`
	Labels            map[string]string        `json:"labels,omitempty"`
	CachedContent     string                   `json:"cachedContent,omitempty"`
	Stream            bool                     `json:"-"` // Internal field to track streaming requests
	IsEmbedding       bool                     `json:"-"` // Internal field to track if this is an embedding request
	IsTranscription   bool                     `json:"-"` // Internal field to track if this is a transcription request
	IsSpeech          bool                     `json:"-"` // Internal field to track if this is a speech request
	IsCountTokens     bool                     `json:"-"` // Internal field to track if this is a count tokens request

	// Bifrost specific field (only parsed when converting from Provider -> Bifrost request)
	Fallbacks []string `json:"fallbacks,omitempty"`
}

// IsStreamingRequested implements the StreamingRequest interface
func (r *GeminiGenerationRequest) IsStreamingRequested() bool {
	return r.Stream
}

// SafetySetting represents safety settings.
type SafetySetting struct {
	// Optional. Determines if the harm block method uses probability or probability
	// and severity scores.
	Method string `json:"method,omitempty"`
	// Required. Harm category.
	Category string `json:"category,omitempty"`
	// Required. The harm block threshold.
	Threshold string `json:"threshold,omitempty"`
}

// SafeExtractSafetySettings safely extracts []SafetySetting from an interface{} with type checking.
// Handles both direct []SafetySetting and JSON-deserialized []interface{} cases.
func SafeExtractSafetySettings(value interface{}) ([]SafetySetting, bool) {
	if value == nil {
		return nil, false
	}
	switch v := value.(type) {
	case []SafetySetting:
		return v, true
	case []interface{}:
		settings := make([]SafetySetting, 0, len(v))
		for _, item := range v {
			if m, ok := item.(map[string]interface{}); ok {
				setting := SafetySetting{}
				if method, ok := m["method"].(string); ok {
					setting.Method = method
				}
				if category, ok := m["category"].(string); ok {
					setting.Category = category
				}
				if threshold, ok := m["threshold"].(string); ok {
					setting.Threshold = threshold
				}
				settings = append(settings, setting)
			} else {
				return nil, false
			}
		}
		return settings, true
	default:
		return nil, false
	}
}

// FunctionCallingConfig represents function calling configuration.
type FunctionCallingConfig struct {
	// Optional. Function calling mode.
	Mode FunctionCallingConfigMode `json:"mode,omitempty"`
	// Optional. Function names to call. Only set when the Mode is ANY. Function names should
	// match [FunctionDeclaration.Name]. With mode set to ANY, model will predict a function
	// call from the set of function names provided.
	AllowedFunctionNames []string `json:"allowedFunctionNames,omitempty"`
}

// FunctionCallingConfigMode represents the function calling config mode.
type FunctionCallingConfigMode string

const (
	// The function calling config mode is unspecified. Should not be used.
	FunctionCallingConfigModeUnspecified FunctionCallingConfigMode = "MODE_UNSPECIFIED"
	// Default model behavior, model decides to predict either function calls or natural
	// language response.
	FunctionCallingConfigModeAuto FunctionCallingConfigMode = "AUTO"
	// Model is constrained to always predicting function calls only. If "allowed_function_names"
	// are set, the predicted function calls will be limited to any one of "allowed_function_names",
	// else the predicted function calls will be any one of the provided "function_declarations".
	FunctionCallingConfigModeAny FunctionCallingConfigMode = "ANY"
	// Model will not predict any function calls. Model behavior is same as when not passing
	// any function declarations.
	FunctionCallingConfigModeNone FunctionCallingConfigMode = "NONE"
	// Model decides to predict either a function call or a natural language response, but
	// will validate function calls with constrained decoding. If "allowed_function_names"
	// are set, the predicted function call will be limited to any one of "allowed_function_names",
	// else the predicted function call will be any one of the provided "function_declarations".
	FunctionCallingConfigModeValidated FunctionCallingConfigMode = "VALIDATED"
)

// LatLng represents a latitude/longitude pair.
// This is expressed as a pair of doubles to represent degrees latitude and
// degrees longitude. Unless specified otherwise, this object must conform to the
// <a href="https://en.wikipedia.org/wiki/World_Geodetic_System#1984_version">
// WGS84 standard</a>. Values must be within normalized ranges.
type LatLng struct {
	// Optional. The latitude in degrees. It must be in the range [-90.0, +90.0].
	Latitude *float64 `json:"latitude,omitempty"`
	// Optional. The longitude in degrees. It must be in the range [-180.0, +180.0]
	Longitude *float64 `json:"longitude,omitempty"`
}

// RetrievalConfig represents retrieval configuration.
type RetrievalConfig struct {
	// Optional. The location of the user.
	LatLng *LatLng `json:"latLng,omitempty"`
	// The language code of the user.
	LanguageCode string `json:"languageCode,omitempty"`
}

// ToolConfig represents tool configuration.
// This config is shared for all tools provided in the request.
type ToolConfig struct {
	// Optional. Function calling config.
	FunctionCallingConfig *FunctionCallingConfig `json:"functionCallingConfig,omitempty"`
	// Optional. Retrieval config.
	RetrievalConfig *RetrievalConfig `json:"retrievalConfig,omitempty"`
}

// FunctionDeclaration defines a function that the model can generate JSON inputs for.
// The inputs are based on `OpenAPI 3.0 specifications
// <https://spec.openapis.org/oas/v3.0.3>`_.
type FunctionDeclaration struct {
	// Optional. Defines the function behavior.
	Behavior Behavior `json:"behavior,omitempty"`
	// Optional. Description and purpose of the function. Model uses it to decide how and
	// whether to call the function.
	Description string `json:"description,omitempty"`
	// Required. The name of the function to call. Must start with a letter or an underscore.
	// Must be a-z, A-Z, 0-9, or contain underscores, dots and dashes, with a maximum length
	// of 64.
	Name string `json:"name,omitempty"`
	// Optional. Describes the parameters to this function in JSON Schema Object format.
	// Reflects the Open API 3.03 Parameter Object. string Key: the name of the parameter.
	// Parameter names are case sensitive. Schema Value: the Schema defining the type used
	// for the parameter. For function with no parameters, this can be left unset. Parameter
	// names must start with a letter or an underscore and must only contain chars a-z,
	// A-Z, 0-9, or underscores with a maximum length of 64. Example with 1 required and
	// 1 optional parameter: type: OBJECT properties: param1: type: STRING param2: type:
	// INTEGER required: - param1
	Parameters *Schema `json:"parameters,omitempty"`
	// Optional. Describes the parameters to the function in JSON Schema format. The schema
	// must describe an object where the properties are the parameters to the function.
	// For example: ``` { "type": "object", "properties": { "name": { "type": "string" },
	// "age": { "type": "integer" } }, "additionalProperties": false, "required": ["name",
	// "age"], "propertyOrdering": ["name", "age"] } ``` This field is mutually exclusive
	// with `parameters`.
	ParametersJSONSchema any `json:"parametersJsonSchema,omitempty"`
	// Optional. Describes the output from this function in JSON Schema format. Reflects
	// the Open API 3.03 Response Object. The Schema defines the type used for the response
	// value of the function.
	Response *Schema `json:"response,omitempty"`
	// Optional. Describes the output from this function in JSON Schema format. The value
	// specified by the schema is the response value of the function. This field is mutually
	// exclusive with `response`.
	ResponseJSONSchema any `json:"responseJsonSchema,omitempty"`
}

// Behavior defines the function behavior. Defaults to `BLOCKING`.
type Behavior string

const (
	// This value is unused.
	BehaviorUnspecified Behavior = "UNSPECIFIED"
	// If set, the system will wait to receive the function response before continuing the
	// conversation.
	BehaviorBlocking Behavior = "BLOCKING"
	// If set, the system will not wait to receive the function response. Instead, it will
	// attempt to handle function responses as they become available while maintaining the
	// conversation between the user and the model.
	BehaviorNonBlocking Behavior = "NON_BLOCKING"
)

// Interval represents a time interval, encoded as a start time (inclusive) and an end time (exclusive).
// The start time must be less than or equal to the end time.
// When the start equals the end time, the interval is an empty interval.
// (matches no time)
// When both start and end are unspecified, the interval matches any time.
type Interval struct {
	// Optional. The start time of the interval.
	StartTime time.Time `json:"startTime,omitempty"`
	// Optional. The end time of the interval.
	EndTime time.Time `json:"endTime,omitempty"`
}

func (i *Interval) UnmarshalJSON(data []byte) error {
	type Alias Interval
	aux := &struct {
		StartTime *time.Time `json:"startTime,omitempty"`
		EndTime   *time.Time `json:"endTime,omitempty"`
		*Alias
	}{
		Alias: (*Alias)(i),
	}

	if err := json.Unmarshal(data, &aux); err != nil {
		return err
	}

	if !reflect.ValueOf(aux.StartTime).IsZero() {
		i.StartTime = time.Time(*aux.StartTime)
	}

	if !reflect.ValueOf(aux.EndTime).IsZero() {
		i.EndTime = time.Time(*aux.EndTime)
	}

	return nil
}

func (i *Interval) MarshalJSON() ([]byte, error) {
	type Alias Interval
	aux := &struct {
		StartTime *time.Time `json:"startTime,omitempty"`
		EndTime   *time.Time `json:"endTime,omitempty"`
		*Alias
	}{
		Alias: (*Alias)(i),
	}

	if !reflect.ValueOf(i.StartTime).IsZero() {
		aux.StartTime = (*time.Time)(&i.StartTime)
	}

	if !reflect.ValueOf(i.EndTime).IsZero() {
		aux.EndTime = (*time.Time)(&i.EndTime)
	}

	return json.Marshal(aux)
}

// GoogleSearch is a tool to support Google Search in Model. Powered by Google.
type GoogleSearch struct {
	// Optional. Filter search results to a specific time range.
	// If customers set a start time, they must set an end time (and vice versa).
	TimeRangeFilter *Interval `json:"timeRangeFilter,omitempty"`
	// Optional. List of domains to be excluded from the search results.
	// The default limit is 2000 domains.
	ExcludeDomains []string `json:"excludeDomains,omitempty"`
}

// DynamicRetrievalConfig describes the options to customize dynamic retrieval.
type DynamicRetrievalConfig struct {
	// Optional. The mode of the predictor to be used in dynamic retrieval.
	Mode string `json:"mode,omitempty"`
	// Optional. The threshold to be used in dynamic retrieval. If empty, a system default
	// value is used.
	DynamicThreshold *float32 `json:"dynamicThreshold,omitempty"`
}

// GoogleSearchRetrieval is a tool to retrieve public web data for grounding, powered by Google.
type GoogleSearchRetrieval struct {
	// Optional. Specifies the dynamic retrieval configuration for the given source.
	DynamicRetrievalConfig *DynamicRetrievalConfig `json:"dynamicRetrievalConfig,omitempty"`
}

// EnterpriseWebSearch is a tool to search public web data, powered by Vertex AI Search and Sec4 compliance.
type EnterpriseWebSearch struct {
	// Optional. List of domains to be excluded from the search results. The default limit
	// is 2000 domains.
	ExcludeDomains []string `json:"excludeDomains,omitempty"`
}

// APIKeyConfig represents configuration for authentication with API key.
type APIKeyConfig struct {
	// Optional. The API key to be used in the request directly.
	APIKeyString string `json:"apiKeyString,omitempty"`
}

// AuthConfigGoogleServiceAccountConfig represents configuration for Google Service Account Authentication.
type AuthConfigGoogleServiceAccountConfig struct {
	// Optional. The service account that the extension execution service runs as. - If
	// the service account is specified, the `iam.serviceAccounts.getAccessToken` permission
	// should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents)
	// on the specified service account. - If not specified, the Vertex AI Extension Service
	// Agent will be used to execute the Extension.
	ServiceAccount string `json:"serviceAccount,omitempty"`
}

// AuthConfigHTTPBasicAuthConfig represents configuration for HTTP Basic Authentication.
type AuthConfigHTTPBasicAuthConfig struct {
	// Required. The name of the SecretManager secret version resource storing the base64
	// encoded credentials. Format: `projects/{project}/secrets/{secrete}/versions/{version}`
	// - If specified, the `secretmanager.versions.access` permission should be granted
	// to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents)
	// on the specified resource.
	CredentialSecret string `json:"credentialSecret,omitempty"`
}

// AuthConfigOauthConfig represents configuration for user oauth.
type AuthConfigOauthConfig struct {
	// Access token for extension endpoint. Only used to propagate token from [[ExecuteExtensionRequest.runtime_auth_config]]
	// at request time.
	AccessToken string `json:"accessToken,omitempty"`
	// The service account used to generate access tokens for executing the Extension. -
	// If the service account is specified, the `iam.serviceAccounts.getAccessToken` permission
	// should be granted to Vertex AI Extension Service Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents)
	// on the provided service account.
	ServiceAccount string `json:"serviceAccount,omitempty"`
}

// AuthConfigOidcConfig represents configuration for user OIDC auth.
type AuthConfigOidcConfig struct {
	// OpenID Connect formatted ID token for extension endpoint. Only used to propagate
	// token from [[ExecuteExtensionRequest.runtime_auth_config]] at request time.
	IDToken string `json:"idToken,omitempty"`
	// The service account used to generate an OpenID Connect (OIDC)-compatible JWT token
	// signed by the Google OIDC Provider (accounts.google.com) for extension endpoint (https://cloud.google.com/iam/docs/create-short-lived-credentials-direct#sa-credentials-oidc).
	// - The audience for the token will be set to the URL in the server URL defined in
	// the OpenAPI spec. - If the service account is provided, the service account should
	// grant `iam.serviceAccounts.getOpenIDToken` permission to Vertex AI Extension Service
	// Agent (https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents).
	ServiceAccount string `json:"serviceAccount,omitempty"`
}

// AuthConfig represents authentication configuration to run the extension.
type AuthConfig struct {
	// Optional. Config for API key auth.
	APIKeyConfig *APIKeyConfig `json:"apiKeyConfig,omitempty"`
	// Type of auth scheme.
	AuthType AuthType `json:"authType,omitempty"`
	// Config for Google Service Account auth.
	GoogleServiceAccountConfig *AuthConfigGoogleServiceAccountConfig `json:"googleServiceAccountConfig,omitempty"`
	// Config for HTTP Basic auth.
	HTTPBasicAuthConfig *AuthConfigHTTPBasicAuthConfig `json:"httpBasicAuthConfig,omitempty"`
	// Config for user oauth.
	OauthConfig *AuthConfigOauthConfig `json:"oauthConfig,omitempty"`
	// Config for user OIDC auth.
	OidcConfig *AuthConfigOidcConfig `json:"oidcConfig,omitempty"`
}

// AuthType represents the type of auth scheme.
type AuthType string

const (
	AuthTypeUnspecified AuthType = "AUTH_TYPE_UNSPECIFIED"
	// No Auth.
	AuthTypeNoAuth AuthType = "NO_AUTH"
	// API Key Auth.
	AuthTypeAPIKeyAuth AuthType = "API_KEY_AUTH"
	// HTTP Basic Auth.
	AuthTypeHTTPBasicAuth AuthType = "HTTP_BASIC_AUTH"
	// Google Service Account Auth.
	AuthTypeGoogleServiceAccountAuth AuthType = "GOOGLE_SERVICE_ACCOUNT_AUTH"
	// OAuth auth.
	AuthTypeOauth AuthType = "OAUTH"
	// OpenID Connect (OIDC) Auth.
	AuthTypeOidcAuth AuthType = "OIDC_AUTH"
)

// GoogleMaps is a tool to support Google Maps in Model.
type GoogleMaps struct {
	// Optional. Auth config for the Google Maps tool.
	AuthConfig *AuthConfig `json:"authConfig,omitempty"`
}

// URLContext is a tool to support URL context retrieval.
type URLContext struct {
}

// ToolComputerUse is a tool to support computer use.
type ToolComputerUse struct {
	// Optional. Required. The environment being operated.
	Environment Environment `json:"environment,omitempty"`
}

// Environment represents the environment being operated.
type Environment string

const (
	// Defaults to browser.
	EnvironmentUnspecified Environment = "ENVIRONMENT_UNSPECIFIED"
	// Operates in a web browser.
	EnvironmentBrowser Environment = "ENVIRONMENT_BROWSER"
)

// APIAuthAPIKeyConfig represents the API secret.
type APIAuthAPIKeyConfig struct {
	// Required. The SecretManager secret version resource name storing API key. e.g. projects/{project}/secrets/{secret}/versions/{version}
	APIKeySecretVersion string `json:"apiKeySecretVersion,omitempty"`
	// The API key string. Either this or `api_key_secret_version` must be set.
	APIKeyString string `json:"apiKeyString,omitempty"`
}

// APIAuth represents the generic reusable API auth config. Deprecated. Please use AuthConfig (google/cloud/aiplatform/master/auth.proto)
// instead.
type APIAuth struct {
	// The API secret.
	APIKeyConfig *APIAuthAPIKeyConfig `json:"apiKeyConfig,omitempty"`
}

// ExternalAPIElasticSearchParams represents the search parameters to use for the ELASTIC_SEARCH spec.
type ExternalAPIElasticSearchParams struct {
	// The ElasticSearch index to use.
	Index string `json:"index,omitempty"`
	// Optional. Number of hits (chunks) to request. When specified, it is passed to Elasticsearch
	// as the `num_hits` param.
	NumHits *int32 `json:"numHits,omitempty"`
	// The ElasticSearch search template to use.
	SearchTemplate string `json:"searchTemplate,omitempty"`
}

// ExternalAPISimpleSearchParams represents the search parameters to use for SIMPLE_SEARCH spec.
type ExternalAPISimpleSearchParams struct {
}

// ExternalAPI retrieves from data source powered by external API for grounding. The external API
// is not owned by Google, but needs to follow the pre-defined API spec.
type ExternalAPI struct {
	// The authentication config to access the API. Deprecated. Please use auth_config instead.
	APIAuth *APIAuth `json:"apiAuth,omitempty"`
	// The API spec that the external API implements.
	APISpec APISpec `json:"apiSpec,omitempty"`
	// The authentication config to access the API.
	AuthConfig *AuthConfig `json:"authConfig,omitempty"`
	// Parameters for the elastic search API.
	ElasticSearchParams *ExternalAPIElasticSearchParams `json:"elasticSearchParams,omitempty"`
	// The endpoint of the external API. The system will call the API at this endpoint to
	// retrieve the data for grounding. Example: https://acme.com:443/search
	Endpoint string `json:"endpoint,omitempty"`
	// Parameters for the simple search API.
	SimpleSearchParams *ExternalAPISimpleSearchParams `json:"simpleSearchParams,omitempty"`
}

// APISpec represents the API spec that the external API implements.
type APISpec string

const (
	// Unspecified API spec. This value should not be used.
	APISpecUnspecified APISpec = "API_SPEC_UNSPECIFIED"
	// Simple search API spec.
	APISpecSimpleSearch APISpec = "SIMPLE_SEARCH"
	// Elastic search API spec.
	APISpecElasticSearch APISpec = "ELASTIC_SEARCH"
)

// VertexAISearchDataStoreSpec defines data stores within engine to filter on in a search call and configurations
// for those data stores. For more information, see https://cloud.google.com/generative-ai-app-builder/docs/reference/rpc/google.cloud.discoveryengine.v1#datastorespec
type VertexAISearchDataStoreSpec struct {
	// Full resource name of DataStore, such as Format: `projects/{project}/locations/{location}/collections/{collection}/dataStores/{dataStore}`
	DataStore string `json:"dataStore,omitempty"`
	// Optional. Filter specification to filter documents in the data store specified by
	// data_store field. For more information on filtering, see [Filtering](https://cloud.google.com/generative-ai-app-builder/docs/filter-search-metadata)
	Filter string `json:"filter,omitempty"`
}

// VertexAISearch retrieves from Vertex AI Search datastore or engine for grounding. datastore and engine
// are mutually exclusive. See https://cloud.google.com/products/agent-builder
type VertexAISearch struct {
	// Specifications that define the specific DataStores to be searched, along with configurations
	// for those data stores. This is only considered for Engines with multiple data stores.
	// It should only be set if engine is used.
	DataStoreSpecs []*VertexAISearchDataStoreSpec `json:"dataStoreSpecs,omitempty"`
	// Optional. Fully-qualified Vertex AI Search data store resource ID. Format: `projects/{project}/locations/{location}/collections/{collection}/dataStores/{dataStore}`
	Datastore string `json:"datastore,omitempty"`
	// Optional. Fully-qualified Vertex AI Search engine resource ID. Format: `projects/{project}/locations/{location}/collections/{collection}/engines/{engine}`
	Engine string `json:"engine,omitempty"`
	// Optional. Filter strings to be passed to the search API.
	Filter string `json:"filter,omitempty"`
	// Optional. Number of search results to return per query. The default value is 10.
	// The maximumm allowed value is 10.
	MaxResults *int32 `json:"maxResults,omitempty"`
}

// VertexRAGStoreRAGResource represents the definition of the RAG resource.
type VertexRAGStoreRAGResource struct {
	// Optional. RAGCorpora resource name. Format: `projects/{project}/locations/{location}/ragCorpora/{rag_corpus}`
	RAGCorpus string `json:"ragCorpus,omitempty"`
	// Optional. rag_file_id. The files should be in the same rag_corpus set in rag_corpus
	// field.
	RAGFileIDs []string `json:"ragFileIds,omitempty"`
}

// RAGRetrievalConfigFilter represents configuration for filters.
type RAGRetrievalConfigFilter struct {
	// Optional. String for metadata filtering.
	MetadataFilter string `json:"metadataFilter,omitempty"`
	// Optional. Only returns contexts with vector distance smaller than the threshold.
	VectorDistanceThreshold *float64 `json:"vectorDistanceThreshold,omitempty"`
	// Optional. Only returns contexts with vector similarity larger than the threshold.
	VectorSimilarityThreshold *float64 `json:"vectorSimilarityThreshold,omitempty"`
}

// RAGRetrievalConfigHybridSearch represents configuration for Hybrid Search.
type RAGRetrievalConfigHybridSearch struct {
	// Optional. Alpha value controls the weight between dense and sparse vector search
	// results. The range is [0, 1], while 0 means sparse vector search only and 1 means
	// dense vector search only. The default value is 0.5 which balances sparse and dense
	// vector search equally.
	Alpha *float64 `json:"alpha,omitempty"`
}

// RAGRetrievalConfigRankingLlmRanker represents configuration for LlmRanker.
type RAGRetrievalConfigRankingLlmRanker struct {
	// Optional. The model name used for ranking. See [Supported models](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#supported-models).
	ModelName string `json:"modelName,omitempty"`
}

// RAGRetrievalConfigRankingRankService represents configuration for Rank Service.
type RAGRetrievalConfigRankingRankService struct {
	// Optional. The model name of the rank service. Format: `semantic-ranker-512@latest`
	ModelName string `json:"modelName,omitempty"`
}

// RAGRetrievalConfigRanking represents configuration for ranking and reranking.
type RAGRetrievalConfigRanking struct {
	// Optional. Config for LlmRanker.
	LlmRanker *RAGRetrievalConfigRankingLlmRanker `json:"llmRanker,omitempty"`
	// Optional. Config for Rank Service.
	RankService *RAGRetrievalConfigRankingRankService `json:"rankService,omitempty"`
}

// RAGRetrievalConfig specifies the context retrieval configuration.
type RAGRetrievalConfig struct {
	// Optional. Config for filters.
	Filter *RAGRetrievalConfigFilter `json:"filter,omitempty"`
	// Optional. Config for Hybrid Search.
	HybridSearch *RAGRetrievalConfigHybridSearch `json:"hybridSearch,omitempty"`
	// Optional. Config for ranking and reranking.
	Ranking *RAGRetrievalConfigRanking `json:"ranking,omitempty"`
	// Optional. The number of contexts to retrieve.
	TopK *int32 `json:"topK,omitempty"`
}

// VertexRAGStore retrieves from Vertex RAG Store for grounding. You can find API default values and
// more details at https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/rag-api-v1#parameters-list
type VertexRAGStore struct {
	// Optional. Deprecated. Please use rag_resources instead.
	RAGCorpora []string `json:"ragCorpora,omitempty"`
	// Optional. The representation of the RAG source. It can be used to specify corpus
	// only or ragfiles. Currently only support one corpus or multiple files from one corpus.
	// In the future we may open up multiple corpora support.
	RAGResources []*VertexRAGStoreRAGResource `json:"ragResources,omitempty"`
	// Optional. The retrieval config for the RAG query.
	RAGRetrievalConfig *RAGRetrievalConfig `json:"ragRetrievalConfig,omitempty"`
	// Optional. Number of top k results to return from the selected corpora.
	SimilarityTopK *int32 `json:"similarityTopK,omitempty"`
	// Optional. Currently only supported for Gemini Multimodal Live API. In Gemini Multimodal
	// Live API, if `store_context` bool is specified, Gemini will leverage it to automatically
	// memorize the interactions between the client and Gemini, and retrieve context when
	// needed to augment the response generation for users' ongoing and future interactions.
	StoreContext *bool `json:"storeContext,omitempty"`
	// Optional. Only return results with vector distance smaller than the threshold.
	VectorDistanceThreshold *float64 `json:"vectorDistanceThreshold,omitempty"`
}

// Retrieval defines a retrieval tool that model can call to access external knowledge.
type Retrieval struct {
	// Optional. Deprecated. This option is no longer supported.
	DisableAttribution bool `json:"disableAttribution,omitempty"`
	// Use data source powered by external API for grounding.
	ExternalAPI *ExternalAPI `json:"externalApi,omitempty"`
	// Set to use data source powered by Vertex AI Search.
	VertexAISearch *VertexAISearch `json:"vertexAiSearch,omitempty"`
	// Set to use data source powered by Vertex RAG store. User data is uploaded via the
	// VertexRAGDataService.
	VertexRAGStore *VertexRAGStore `json:"vertexRagStore,omitempty"`
}

// ToolCodeExecution is a tool that executes code generated by the model, and automatically returns the result
// to the model. See also [ExecutableCode]and [CodeExecutionResult] which are input
// and output to this tool.
type ToolCodeExecution struct {
}

// Tool details of a tool that the model may use to generate a response.
type Tool struct {
	// Optional. List of function declarations that the tool supports.
	FunctionDeclarations []*FunctionDeclaration `json:"functionDeclarations,omitempty"`
	// Optional. Retrieval tool type. System will always execute the provided retrieval
	// tool(s) to get external knowledge to answer the prompt. Retrieval results are presented
	// to the model for generation.
	Retrieval *Retrieval `json:"retrieval,omitempty"`
	// Optional. Google Search tool type. Specialized retrieval tool
	// that is powered by Google Search.
	GoogleSearch *GoogleSearch `json:"googleSearch,omitempty"`
	// Optional. GoogleSearchRetrieval tool type. Specialized retrieval tool that is powered
	// by Google search.
	GoogleSearchRetrieval *GoogleSearchRetrieval `json:"googleSearchRetrieval,omitempty"`
	// Optional. Enterprise web search tool type. Specialized retrieval
	// tool that is powered by Vertex AI Search and Sec4 compliance.
	EnterpriseWebSearch *EnterpriseWebSearch `json:"enterpriseWebSearch,omitempty"`
	// Optional. Google Maps tool type. Specialized retrieval tool
	// that is powered by Google Maps.
	GoogleMaps *GoogleMaps `json:"googleMaps,omitempty"`
	// Optional. Tool to support URL context retrieval.
	URLContext *URLContext `json:"urlContext,omitempty"`
	// Optional. Tool to support the model interacting directly with the
	// computer. If enabled, it automatically populates computer-use specific
	// Function Declarations.
	ComputerUse *ToolComputerUse `json:"computerUse,omitempty"`
	// Optional. CodeExecution tool type. Enables the model to execute code as part of generation.
	CodeExecution *ToolCodeExecution `json:"codeExecution,omitempty"`
}

// GenerationConfig represents generation configuration. You can find API default values and more details at https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#generationconfig
// and https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/content-generation-parameters.
type GenerationConfig struct {
	// Optional. Config for model selection.
	ModelSelectionConfig *ModelSelectionConfig `json:"modelSelectionConfig,omitempty"`
	// Optional. If enabled, audio timestamp will be included in the request to the model.
	AudioTimestamp bool `json:"audioTimestamp,omitempty"`
	// Optional. Number of candidates to generate. If empty, the system will choose a default
	// value (currently 1).
	CandidateCount int32 `json:"candidateCount,omitempty"`
	// Optional. If enabled, the model will detect emotions and adapt its responses accordingly.
	EnableAffectiveDialog *bool `json:"enableAffectiveDialog,omitempty"`
	// Optional. Frequency penalties.
	FrequencyPenalty *float64 `json:"frequencyPenalty,omitempty"`
	// Optional. Logit probabilities.
	Logprobs *int32 `json:"logprobs,omitempty"`
	// Optional. The maximum number of output tokens to generate per message. If empty,
	// API will use a default value. The default value varies by model.
	MaxOutputTokens int32 `json:"maxOutputTokens,omitempty"`
	// Optional. If specified, the media resolution specified will be used.
	MediaResolution string `json:"mediaResolution,omitempty"`
	// Optional. Positive penalties.
	PresencePenalty *float64 `json:"presencePenalty,omitempty"`
	// Optional. Output schema of the generated response. This is an alternative to `response_schema`
	// that accepts [JSON Schema](https://json-schema.org/). If set, `response_schema` must
	// be omitted, but `response_mime_type` is required. While the full JSON Schema may
	// be sent, not all features are supported. Specifically, only the following properties
	// are supported: - `$id` - `$defs` - `$ref` - `$anchor` - `type` - `format` - `title`
	// - `description` - `enum` (for strings and numbers) - `items` - `prefixItems` - `minItems`
	// - `maxItems` - `minimum` - `maximum` - `anyOf` - `oneOf` (interpreted the same as
	// `anyOf`) - `properties` - `additionalProperties` - `required` The non-standard `propertyOrdering`
	// property may also be set. Cyclic references are unrolled to a limited degree and,
	// as such, may only be used within non-required properties. (Nullable properties are
	// not sufficient.) If `$ref` is set on a sub-schema, no other properties, except for
	// than those starting as a `$`, may be set.
	ResponseJSONSchema any `json:"responseJsonSchema,omitempty"`
	// Optional. If true, export the logprobs results in response.
	ResponseLogprobs bool `json:"responseLogprobs,omitempty"`
	// Optional. Output response mimetype of the generated candidate text. Supported mimetype:
	// - `text/plain`: (default) Text output. - `application/json`: JSON response in the
	// candidates. The model needs to be prompted to output the appropriate response type,
	// otherwise the behavior is undefined. This is a preview feature.
	ResponseMIMEType string `json:"responseMimeType,omitempty"`
	// Optional. The modalities of the response.
	ResponseModalities []Modality `json:"responseModalities,omitempty"`
	// Optional. The `Schema` object allows the definition of input and output data types.
	// These types can be objects, but also primitives and arrays. Represents a select subset
	// of an [OpenAPI 3.0 schema object](https://spec.openapis.org/oas/v3.0.3#schema). If
	// set, a compatible response_mime_type must also be set. Compatible mimetypes: `application/json`:
	// Schema for JSON response.
	ResponseSchema *Schema `json:"responseSchema,omitempty"`
	// Optional. Routing configuration.
	RoutingConfig *GenerationConfigRoutingConfig `json:"routingConfig,omitempty"`
	// Optional. Seed.
	Seed *int32 `json:"seed,omitempty"`
	// Optional. The speech generation config.
	SpeechConfig *SpeechConfig `json:"speechConfig,omitempty"`
	// Optional. Stop sequences.
	StopSequences []string `json:"stopSequences,omitempty"`
	// Optional. Controls the randomness of predictions.
	Temperature *float64 `json:"temperature,omitempty"`
	// Optional. Config for thinking features. An error will be returned if this field is
	// set for models that don't support thinking.
	ThinkingConfig *GenerationConfigThinkingConfig `json:"thinkingConfig,omitempty"`
	// Optional. If specified, top-k sampling will be used.
	TopK *int `json:"topK,omitempty"`
	// Optional. If specified, nucleus sampling will be used.
	TopP *float64 `json:"topP,omitempty"`
}

// ModelSelectionConfig represents configuration for model selection.
type ModelSelectionConfig struct {
	// Optional. Options for feature selection preference.
	FeatureSelectionPreference string `json:"featureSelectionPreference,omitempty"`
}

// Modality represents server content modalities.
type Modality string

const (
	// The modality is unspecified.
	ModalityUnspecified Modality = "MODALITY_UNSPECIFIED"
	// Indicates the model should return text
	ModalityText Modality = "TEXT"
	// Indicates the model should return images.
	ModalityImage Modality = "IMAGE"
	// Indicates the model should return audio.
	ModalityAudio Modality = "AUDIO"
)

// Schema is used to define the format of input/output data.
// Represents a select subset of an [OpenAPI 3.0 schema
// object](https://spec.openapis.org/oas/v3.0.3#schema-object). More fields may
// be added in the future as needed.
// You can find more details and examples at https://spec.openapis.org/oas/v3.0.3.html#schema-object
type Schema struct {
	// Optional. The value should be validated against any (one or more) of the subschemas
	// in the list.
	AnyOf []*Schema `json:"anyOf,omitempty"`
	// Optional. Default value of the data.
	Default any `json:"default,omitempty"`
	// Optional. The description of the data.
	Description string `json:"description,omitempty"`
	// Optional. Possible values of the element of primitive type with enum format. Examples:
	// 1. We can define direction as : {type:STRING, format:enum, enum:["EAST", NORTH",
	// "SOUTH", "WEST"]} 2. We can define apartment number as : {type:INTEGER, format:enum,
	// enum:["101", "201", "301"]}
	Enum []string `json:"enum,omitempty"`
	// Optional. Example of the object. Will only populated when the object is the root.
	Example any `json:"example,omitempty"`
	// Optional. The format of the data. Supported formats: for NUMBER type: "float", "double"
	// for INTEGER type: "int32", "int64" for STRING type: "email", "byte", etc
	Format string `json:"format,omitempty"`
	// Optional. SCHEMA FIELDS FOR TYPE ARRAY Schema of the elements of Type.ARRAY.
	Items *Schema `json:"items,omitempty"`
	// Optional. Maximum number of the elements for Type.ARRAY.
	MaxItems *int64 `json:"maxItems,omitempty,string"`
	// Optional. Maximum length of the Type.STRING
	MaxLength *int64 `json:"maxLength,omitempty,string"`
	// Optional. Maximum number of the properties for Type.OBJECT.
	MaxProperties *int64 `json:"maxProperties,omitempty,string"`
	// Optional. Maximum value of the Type.INTEGER and Type.NUMBER
	Maximum *float64 `json:"maximum,omitempty"`
	// Optional. Minimum number of the elements for Type.ARRAY.
	MinItems *int64 `json:"minItems,omitempty,string"`
	// Optional. SCHEMA FIELDS FOR TYPE STRING Minimum length of the Type.STRING
	MinLength *int64 `json:"minLength,omitempty,string"`
	// Optional. Minimum number of the properties for Type.OBJECT.
	MinProperties *int64 `json:"minProperties,omitempty,string"`
	// Optional. Minimum value of the Type.INTEGER and Type.NUMBER.
	Minimum *float64 `json:"minimum,omitempty"`
	// Optional. Indicates if the value may be null.
	Nullable *bool `json:"nullable,omitempty"`
	// Optional. Pattern of the Type.STRING to restrict a string to a regular expression.
	Pattern string `json:"pattern,omitempty"`
	// Optional. SCHEMA FIELDS FOR TYPE OBJECT Properties of Type.OBJECT.
	Properties map[string]*Schema `json:"properties,omitempty"`
	// Optional. The order of the properties. Not a standard field in open API spec. Only
	// used to support the order of the properties.
	PropertyOrdering []string `json:"propertyOrdering,omitempty"`
	// Optional. Required properties of Type.OBJECT.
	Required []string `json:"required,omitempty"`
	// Optional. The title of the Schema.
	Title string `json:"title,omitempty"`
	// Optional. The type of the data.
	Type Type `json:"type,omitempty"`
}

// Type represents the type of the data.
type Type string

const (
	// Not specified, should not be used.
	TypeUnspecified Type = "TYPE_UNSPECIFIED"
	// OpenAPI string type
	TypeString Type = "STRING"
	// OpenAPI number type
	TypeNumber Type = "NUMBER"
	// OpenAPI integer type
	TypeInteger Type = "INTEGER"
	// OpenAPI boolean type
	TypeBoolean Type = "BOOLEAN"
	// OpenAPI array type
	TypeArray Type = "ARRAY"
	// OpenAPI object type
	TypeObject Type = "OBJECT"
	// NULL type
	TypeNULL Type = "NULL"
)

// GenerationConfigRoutingConfig represents the configuration for routing the request to a specific model.
type GenerationConfigRoutingConfig struct {
	// Automated routing.
	AutoMode *GenerationConfigRoutingConfigAutoRoutingMode `json:"autoMode,omitempty"`
	// Manual routing.
	ManualMode *GenerationConfigRoutingConfigManualRoutingMode `json:"manualMode,omitempty"`
}

// GenerationConfigRoutingConfigAutoRoutingMode represents automated routing.
type GenerationConfigRoutingConfigAutoRoutingMode struct {
	// The model routing preference.
	ModelRoutingPreference string `json:"modelRoutingPreference,omitempty"`
}

// GenerationConfigRoutingConfigManualRoutingMode represents manual routing.
type GenerationConfigRoutingConfigManualRoutingMode struct {
	// The model name to use. Only the public LLM models are accepted. See [Supported models](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference#supported-models).
	ModelName string `json:"modelName,omitempty"`
}

// PrebuiltVoiceConfig represents the configuration for the prebuilt speaker to use.
type PrebuiltVoiceConfig struct {
	// Optional. The name of the prebuilt voice to use.
	VoiceName string `json:"voice_name,omitempty"`
}

// UnmarshalJSON implements custom JSON unmarshaling for PrebuiltVoiceConfig.
// This handles the voice_name field which comes as snake_case from the Gemini SDK.
func (p *PrebuiltVoiceConfig) UnmarshalJSON(data []byte) error {
	type Alias struct {
		VoiceName string `json:"voice_name,omitempty"`
	}
	var aux Alias
	if err := json.Unmarshal(data, &aux); err != nil {
		return err
	}
	p.VoiceName = aux.VoiceName
	return nil
}

// MarshalJSON implements custom JSON marshaling for PrebuiltVoiceConfig.
// This outputs voiceName as camelCase which is what the Gemini API expects.
func (p PrebuiltVoiceConfig) MarshalJSON() ([]byte, error) {
	type Alias struct {
		VoiceName string `json:"voiceName,omitempty"`
	}
	return json.Marshal(Alias(p))
}

// VoiceConfig represents the configuration for the voice to use.
type VoiceConfig struct {
	// Optional. The configuration for the speaker to use.
	PrebuiltVoiceConfig *PrebuiltVoiceConfig `json:"prebuilt_voice_config,omitempty"`
}

// UnmarshalJSON implements custom JSON unmarshaling for VoiceConfig.
// This handles the prebuilt_voice_config field which comes as snake_case from the Gemini SDK.
func (v *VoiceConfig) UnmarshalJSON(data []byte) error {
	type Alias struct {
		PrebuiltVoiceConfig *PrebuiltVoiceConfig `json:"prebuilt_voice_config,omitempty"`
	}
	var aux Alias
	if err := json.Unmarshal(data, &aux); err != nil {
		return err
	}
	v.PrebuiltVoiceConfig = aux.PrebuiltVoiceConfig
	return nil
}

// MarshalJSON implements custom JSON marshaling for VoiceConfig.
// This outputs prebuiltVoiceConfig as camelCase which is what the Gemini API expects.
func (v VoiceConfig) MarshalJSON() ([]byte, error) {
	type Alias struct {
		PrebuiltVoiceConfig *PrebuiltVoiceConfig `json:"prebuiltVoiceConfig,omitempty"`
	}
	return json.Marshal(Alias(v))
}

// SpeakerVoiceConfig represents the configuration for the speaker to use.
type SpeakerVoiceConfig struct {
	// Optional. The name of the speaker to use. Should be the same as in the prompt.
	Speaker string `json:"speaker,omitempty"`
	// Optional. The configuration for the voice to use.
	VoiceConfig *VoiceConfig `json:"voiceConfig,omitempty"`
}

// MultiSpeakerVoiceConfig represents the configuration for the multi-speaker setup.
type MultiSpeakerVoiceConfig struct {
	// Optional. The configuration for the speakers to use.
	SpeakerVoiceConfigs []*SpeakerVoiceConfig `json:"speakerVoiceConfigs,omitempty"`
}

// SpeechConfig represents the speech generation configuration.
type SpeechConfig struct {
	// Optional. The configuration for the speaker to use.
	VoiceConfig *VoiceConfig `json:"voice_config,omitempty"`
	// Optional. The configuration for the multi-speaker setup.
	// Mutually exclusive with the voiceConfig field.
	MultiSpeakerVoiceConfig *MultiSpeakerVoiceConfig `json:"multiSpeakerVoiceConfig,omitempty"`
	// Optional. Language code (ISO 639, e.g., en-US) for speech synthesis.
	// Only available for Live API.
	LanguageCode string `json:"languageCode,omitempty"`
}

// GenerationConfigThinkingConfig represents configuration for thinking features.
type GenerationConfigThinkingConfig struct {
	// Optional. Indicates whether to include thoughts in the response. If true, thoughts
	// are returned only when available.
	IncludeThoughts bool `json:"includeThoughts,omitempty"`
	// Optional. Indicates the thinking budget in tokens.
	ThinkingBudget *int32 `json:"thinkingBudget,omitempty"`

	// Optional. Indicates the thinking level.
	ThinkingLevel *string `json:"thinkingLevel,omitempty"`
}

// Gemini API supports Camel case but genai sdk sends thinking fields as snake_case
// UnmarshalJSON implements custom JSON unmarshaling to support both camelCase and snake_case
func (tc *GenerationConfigThinkingConfig) UnmarshalJSON(data []byte) error {
	// Define an auxiliary struct with both camelCase and snake_case tags
	type Alias struct {
		IncludeThoughts      *bool   `json:"includeThoughts"`
		IncludeThoughtsSnake *bool   `json:"include_thoughts"`
		ThinkingBudget       *int32  `json:"thinkingBudget"`
		ThinkingBudgetSnake  *int32  `json:"thinking_budget"`
		ThinkingLevel        *string `json:"thinkingLevel"`
		ThinkingLevelSnake   *string `json:"thinking_level"`
	}

	var aux Alias
	if err := sonic.Unmarshal(data, &aux); err != nil {
		return err
	}

	// Prefer camelCase, fall back to snake_case
	if aux.IncludeThoughts != nil {
		tc.IncludeThoughts = *aux.IncludeThoughts
	} else if aux.IncludeThoughtsSnake != nil {
		tc.IncludeThoughts = *aux.IncludeThoughtsSnake
	}

	if aux.ThinkingBudget != nil {
		tc.ThinkingBudget = aux.ThinkingBudget
	} else if aux.ThinkingBudgetSnake != nil {
		tc.ThinkingBudget = aux.ThinkingBudgetSnake
	}

	if aux.ThinkingLevel != nil {
		tc.ThinkingLevel = aux.ThinkingLevel
	} else if aux.ThinkingLevelSnake != nil {
		tc.ThinkingLevel = aux.ThinkingLevelSnake
	}

	return nil
}

type GeminiBatchEmbeddingRequest struct {
	Requests []GeminiEmbeddingRequest `json:"requests,omitempty"`
}

// GeminiEmbeddingRequest represents a single embedding request in a batch.
type GeminiEmbeddingRequest struct {
	Content              *Content `json:"content,omitempty"`
	TaskType             *string  `json:"taskType,omitempty"`
	Title                *string  `json:"title,omitempty"`
	OutputDimensionality *int     `json:"outputDimensionality,omitempty"`
	Model                string   `json:"model,omitempty"`
}

// Content contains the multi-part content of a message.
type Content struct {
	// Optional. List of parts that constitute a single message. Each part may have
	// a different IANA MIME type.
	Parts []*Part `json:"parts,omitempty"`
	// Optional. The producer of the content. Must be either 'user' or
	// 'model'. Useful to set for multi-turn conversations, otherwise can be
	// empty. If role is not specified, SDK will determine the role.
	Role string `json:"role,omitempty"`
}

// Part is a datatype containing media content.
// Exactly one field within a Part should be set, representing the specific type
// of content being conveyed. Using multiple fields within the same `Part`
// instance is considered invalid.
type Part struct {
	// Optional. Metadata for a given video.
	VideoMetadata *VideoMetadata `json:"videoMetadata,omitempty"`
	// Optional. Indicates if the part is thought from the model.
	Thought bool `json:"thought,omitempty"`
	// Optional. Inlined bytes data.
	InlineData *Blob `json:"inlineData,omitempty"`
	// Optional. URI based data.
	FileData *FileData `json:"fileData,omitempty"`
	// Optional. An opaque signature for the thought so it can be reused in subsequent requests.
	ThoughtSignature []byte `json:"thoughtSignature,omitempty"`
	// Optional. Result of executing the [ExecutableCode].
	CodeExecutionResult *CodeExecutionResult `json:"codeExecutionResult,omitempty"`
	// Optional. Code generated by the model that is meant to be executed.
	ExecutableCode *ExecutableCode `json:"executableCode,omitempty"`
	// Optional. A predicted [FunctionCall] returned from the model that contains a string
	// representing the [FunctionDeclaration.Name] with the parameters and their values.
	FunctionCall *FunctionCall `json:"functionCall,omitempty"`
	// Optional. The result output of a [FunctionCall] that contains a string representing
	// the [FunctionDeclaration.Name] and a structured JSON object containing any output
	// from the function call. It is used as context to the model.
	FunctionResponse *FunctionResponse `json:"functionResponse,omitempty"`
	// Optional. Text part (can be code).
	Text string `json:"text,omitempty"`
}

// UnmarshalJSON implements custom JSON unmarshaling for Part.
// This handles the thoughtSignature field which can be sent as a base64-encoded string from the Google GenAI SDK.
func (p *Part) UnmarshalJSON(data []byte) error {
	type PartAlias struct {
		VideoMetadata       *VideoMetadata       `json:"videoMetadata,omitempty"`
		Thought             bool                 `json:"thought,omitempty"`
		InlineData          *Blob                `json:"inlineData,omitempty"`
		FileData            *FileData            `json:"fileData,omitempty"`
		ThoughtSignature    string               `json:"thoughtSignature,omitempty"`
		CodeExecutionResult *CodeExecutionResult `json:"codeExecutionResult,omitempty"`
		ExecutableCode      *ExecutableCode      `json:"executableCode,omitempty"`
		FunctionCall        *FunctionCall        `json:"functionCall,omitempty"`
		FunctionResponse    *FunctionResponse    `json:"functionResponse,omitempty"`
		Text                string               `json:"text,omitempty"`
	}

	var aux PartAlias
	if err := json.Unmarshal(data, &aux); err != nil {
		return err
	}

	p.VideoMetadata = aux.VideoMetadata
	p.Thought = aux.Thought
	p.InlineData = aux.InlineData
	p.FileData = aux.FileData
	p.CodeExecutionResult = aux.CodeExecutionResult
	p.ExecutableCode = aux.ExecutableCode
	p.FunctionCall = aux.FunctionCall
	p.FunctionResponse = aux.FunctionResponse
	p.Text = aux.Text

	if aux.ThoughtSignature != "" {
		// Convert URL-safe base64 to standard base64
		standardBase64 := strings.ReplaceAll(strings.ReplaceAll(aux.ThoughtSignature, "_", "/"), "-", "+")
		// Add padding if necessary
		switch len(standardBase64) % 4 {
		case 2:
			standardBase64 += "=="
		case 3:
			standardBase64 += "="
		}
		decoded, err := base64.StdEncoding.DecodeString(standardBase64)
		if err != nil {
			return fmt.Errorf("failed to decode base64 thoughtSignature: %v", err)
		}
		p.ThoughtSignature = decoded
	}

	return nil
}

// Blob represents content blob.
type Blob struct {
	// Optional. Display name of the blob. Used to provide a label or filename to distinguish
	// blobs. This field is not currently used in the Gemini GenerateContent calls.
	DisplayName string `json:"displayName,omitempty"`
	// Required. Raw bytes.
	Data []byte `json:"data,omitempty"`
	// Required. The IANA standard MIME type of the source data.
	MIMEType string `json:"mimeType,omitempty"`
}

// UnmarshalJSON implements custom JSON unmarshaling for Blob.
// This handles the data field which can be sent as a base64-encoded string from the Google GenAI SDK.
func (b *Blob) UnmarshalJSON(data []byte) error {
	type BlobAlias struct {
		DisplayName string `json:"displayName,omitempty"`
		Data        string `json:"data,omitempty"`
		MIMEType    string `json:"mimeType,omitempty"`
	}

	var aux BlobAlias
	if err := json.Unmarshal(data, &aux); err != nil {
		return err
	}

	b.DisplayName = aux.DisplayName
	b.MIMEType = aux.MIMEType

	if aux.Data != "" {
		// Convert URL-safe base64 to standard base64
		standardBase64 := strings.ReplaceAll(strings.ReplaceAll(aux.Data, "_", "/"), "-", "+")
		// Add padding if necessary
		switch len(standardBase64) % 4 {
		case 2:
			standardBase64 += "=="
		case 3:
			standardBase64 += "="
		}
		decoded, err := base64.StdEncoding.DecodeString(standardBase64)
		if err != nil {
			return fmt.Errorf("failed to decode base64 data: %v", err)
		}
		b.Data = decoded
	}

	return nil
}

// MarshalJSON implements custom JSON marshaling for Blob.
// This ensures the data field is properly base64-encoded when sending to the Gemini API.
func (b Blob) MarshalJSON() ([]byte, error) {
	type BlobAlias struct {
		DisplayName string `json:"displayName,omitempty"`
		Data        string `json:"data,omitempty"`
		MIMEType    string `json:"mimeType,omitempty"`
	}

	aux := BlobAlias{
		DisplayName: b.DisplayName,
		MIMEType:    b.MIMEType,
	}

	if len(b.Data) > 0 {
		// Use standard base64 encoding to match Google GenAI SDK
		aux.Data = base64.StdEncoding.EncodeToString(b.Data)
	}

	return json.Marshal(aux)
}

// VideoMetadata describes how the video in the Part should be used by the model.
type VideoMetadata struct {
	// Optional. The frame rate of the video sent to the model. If not specified, the
	// default value will be 1.0. The FPS range is (0.0, 24.0].
	FPS *float64 `json:"fps,omitempty"`
	// Optional. The end offset of the video.
	EndOffset time.Duration `json:"endOffset,omitempty"`
	// Optional. The start offset of the video.
	StartOffset time.Duration `json:"startOffset,omitempty"`
}

// CodeExecutionResult represents the result of executing the [ExecutableCode]. Only generated when using the [CodeExecution]
// tool, and always follows a `part` containing the [ExecutableCode].
type CodeExecutionResult struct {
	// Required. Outcome of the code execution.
	Outcome Outcome `json:"outcome,omitempty"`
	// Optional. Contains stdout when code execution is successful, stderr or other description
	// otherwise.
	Output string `json:"output,omitempty"`
}

// Outcome of the code execution.
type Outcome string

const (
	// Unspecified status. This value should not be used.
	OutcomeUnspecified Outcome = "OUTCOME_UNSPECIFIED"
	// Code execution completed successfully.
	OutcomeOK Outcome = "OUTCOME_OK"
	// Code execution finished but with a failure. `stderr` should contain the reason.
	OutcomeFailed Outcome = "OUTCOME_FAILED"
	// Code execution ran for too long, and was cancelled. There may or may not be a partial
	// output present.
	OutcomeDeadlineExceeded Outcome = "OUTCOME_DEADLINE_EXCEEDED"
)

// ExecutableCode is code generated by the model that is meant to be executed, and the result returned
// to the model. Generated when using the [CodeExecution] tool, in which the code will
// be automatically executed, and a corresponding [CodeExecutionResult] will also be
// generated.
type ExecutableCode struct {
	// Required. The code to be executed.
	Code string `json:"code,omitempty"`
	// Required. Programming language of the `code`.
	Language string `json:"language,omitempty"`
}

// FileData represents URI based data.
type FileData struct {
	// Optional. Display name of the file data. Used to provide a label or filename to distinguish
	// file datas. It is not currently used in the Gemini GenerateContent calls.
	DisplayName string `json:"displayName,omitempty"`
	// Optional. Required. URI.
	FileURI string `json:"fileUri,omitempty"`
	// Optional. Required. The IANA standard MIME type of the source data.
	MIMEType string `json:"mimeType,omitempty"`
}

// FunctionCall represents a function call.
type FunctionCall struct {
	// Optional. The unique ID of the function call. If populated, the client to execute
	// the
	// `function_call` and return the response with the matching `id`.
	ID string `json:"id,omitempty"`
	// Optional. The function parameters and values in JSON object format. See [FunctionDeclaration.parameters]
	// for parameter details.
	Args map[string]any `json:"args,omitempty"`
	// Required. The name of the function to call. Matches [FunctionDeclaration.Name].
	Name string `json:"name,omitempty"`
}

// FunctionResponse represents a function response.
type FunctionResponse struct {
	// Optional. Signals that function call continues, and more responses will be returned,
	// turning the function call into a generator. Is only applicable to NON_BLOCKING function
	// calls (see FunctionDeclaration.behavior for details), ignored otherwise. If false,
	// the default, future responses will not be considered. Is only applicable to NON_BLOCKING
	// function calls, is ignored otherwise. If set to false, future responses will not
	// be considered. It is allowed to return empty `response` with `will_continue=False`
	// to signal that the function call is finished.
	WillContinue *bool `json:"willContinue,omitempty"`
	// Optional. Specifies how the response should be scheduled in the conversation. Only
	// applicable to NON_BLOCKING function calls, is ignored otherwise. Defaults to WHEN_IDLE.
	Scheduling string `json:"scheduling,omitempty"`
	// Optional. The ID of the function call this response is for. Populated by the client
	// to match the corresponding function call `id`.
	ID string `json:"id,omitempty"`
	// Required. The name of the function to call. Matches [FunctionDeclaration.name] and
	// [FunctionCall.name].
	Name string `json:"name,omitempty"`
	// Required. The function response in JSON object format. Use "output" key to specify
	// function output and "error" key to specify error details (if any). If "output" and
	// "error" keys are not specified, then whole "response" is treated as function output.
	Response map[string]any `json:"response,omitempty"`
}

// ==================== RESPONSE TYPES ====================

// GeminiEmbeddingResponse represents a Google GenAI embedding response.
type GeminiEmbeddingResponse struct {
	Embeddings []GeminiEmbedding     `json:"embeddings"`
	Metadata   *EmbedContentMetadata `json:"metadata,omitempty"`
}

// GeminiEmbedding represents a single embedding in the response
type GeminiEmbedding struct {
	Values     []float32                   `json:"values"`
	Statistics *ContentEmbeddingStatistics `json:"statistics,omitempty"`
}

// EmbedContentMetadata represents request-level metadata for Vertex API
type EmbedContentMetadata struct {
	BillableCharacterCount int32 `json:"billableCharacterCount,omitempty"`
}

// ContentEmbeddingStatistics represents statistics of the input text
type ContentEmbeddingStatistics struct {
	TokenCount int32 `json:"tokenCount,omitempty"`
}

// LogprobsResultCandidate represents a candidate for the logprobs token and score.
type LogprobsResultCandidate struct {
	// The candidate's log probability.
	LogProbability float32 `json:"logProbability,omitempty"`
	// The candidate's token string value.
	Token string `json:"token,omitempty"`
	// The candidate's token ID value.
	TokenID int32 `json:"tokenId,omitempty"`
}

// LogprobsResultTopCandidates represents candidates with top log probabilities at each decoding step.
type LogprobsResultTopCandidates struct {
	// Sorted by log probability in descending order.
	Candidates []*LogprobsResultCandidate `json:"candidates,omitempty"`
}

// LogprobsResult represents logprobs result.
type LogprobsResult struct {
	// Length = total number of decoding steps. The chosen candidates may or may not be
	// in top_candidates.
	ChosenCandidates []*LogprobsResultCandidate `json:"chosenCandidates,omitempty"`
	// Length = total number of decoding steps.
	TopCandidates []*LogprobsResultTopCandidates `json:"topCandidates,omitempty"`
}

// SafetyRating represents safety rating corresponding to the generated content.
type SafetyRating struct {
	// Output only. Indicates whether the content was filtered out because of this rating.
	Blocked bool `json:"blocked,omitempty"`
	// Output only. Harm category.
	Category string `json:"category,omitempty"`
	// Output only. The overwritten threshold for the safety category of Gemini 2.0 image
	// out. If minors are detected in the output image, the threshold of each safety category
	// will be overwritten if user sets a lower threshold.
	OverwrittenThreshold string `json:"overwrittenThreshold,omitempty"`
	// Output only. Harm probability levels in the content.
	Probability string `json:"probability,omitempty"`
	// Output only. Harm probability score.
	ProbabilityScore float32 `json:"probabilityScore,omitempty"`
	// Output only. Harm severity levels in the content.
	Severity string `json:"severity,omitempty"`
	// Output only. Harm severity score.
	SeverityScore float32 `json:"severityScore,omitempty"`
}

// URLMetadata represents context for a single URL retrieval.
type URLMetadata struct {
	// Optional. The URL retrieved by the tool.
	RetrievedURL string `json:"retrievedUrl,omitempty"`
	// Optional. Status of the URL retrieval.
	URLRetrievalStatus string `json:"urlRetrievalStatus,omitempty"`
}

// URLContextMetadata represents metadata related to URL context retrieval tool.
type URLContextMetadata struct {
	// Optional. List of URL context.
	URLMetadata []*URLMetadata `json:"urlMetadata,omitempty"`
}

// Candidate represents a response candidate generated from the model.
type Candidate struct {
	// Optional. Contains the multi-part content of the response.
	Content *Content `json:"content,omitempty"`
	// Optional. Source attribution of the generated content.
	CitationMetadata *map[string]any `json:"citationMetadata,omitempty"`
	// Optional. Describes the reason the model stopped generating tokens.
	FinishMessage string `json:"finishMessage,omitempty"`
	// Optional. Number of tokens for this candidate.
	// This field is only available in the Gemini API.
	TokenCount int32 `json:"tokenCount,omitempty"`
	// Optional. The reason why the model stopped generating tokens.
	// If empty, the model has not stopped generating the tokens.
	FinishReason FinishReason `json:"finishReason,omitempty"`
	// Optional. Metadata related to URL context retrieval tool.
	URLContextMetadata *URLContextMetadata `json:"urlContextMetadata,omitempty"`
	// Output only. Average log probability score of the candidate.
	AvgLogprobs float64 `json:"avgLogprobs,omitempty"`
	// Output only. Metadata specifies sources used to ground generated content.
	GroundingMetadata *map[string]any `json:"groundingMetadata,omitempty"`
	// Output only. Index of the candidate.
	Index int32 `json:"index,omitempty"`
	// Output only. Log-likelihood scores for the response tokens and top tokens
	LogprobsResult *LogprobsResult `json:"logprobsResult,omitempty"`
	// Output only. List of ratings for the safety of a response candidate. There is at
	// most one rating per category.
	SafetyRatings []*SafetyRating `json:"safetyRatings,omitempty"`
}

// GenerateContentResponsePromptFeedback represents content filter results for a prompt sent in the request.
type GenerateContentResponsePromptFeedback struct {
	// Output only. Blocked reason.
	BlockReason string `json:"blockReason,omitempty"`
	// Output only. A readable block reason message.
	BlockReasonMessage string `json:"blockReasonMessage,omitempty"`
	// Output only. Safety ratings.
	SafetyRatings []*SafetyRating `json:"safetyRatings,omitempty"`
}

// ModalityTokenCount represents token counting info for a single modality.
type ModalityTokenCount struct {
	// Optional. The modality associated with this token count.
	Modality string `json:"modality,omitempty"`
	// Number of tokens.
	TokenCount int32 `json:"tokenCount,omitempty"`
}

// GenerateContentResponseUsageMetadata represents usage metadata about response(s).
type GenerateContentResponseUsageMetadata struct {
	// Output only. List of modalities of the cached content in the request input.
	CacheTokensDetails []*ModalityTokenCount `json:"cacheTokensDetails,omitempty"`
	// Output only. Number of tokens in the cached part in the input (the cached content).
	CachedContentTokenCount int32 `json:"cachedContentTokenCount,omitempty"`
	// Number of tokens in the response(s). This includes all the generated response candidates.
	CandidatesTokenCount int32 `json:"candidatesTokenCount,omitempty"`
	// Output only. List of modalities that were returned in the response.
	CandidatesTokensDetails []*ModalityTokenCount `json:"candidatesTokensDetails,omitempty"`
	// Number of tokens in the prompt. When cached_content is set, this is still the total
	// effective prompt size meaning this includes the number of tokens in the cached content.
	PromptTokenCount int32 `json:"promptTokenCount,omitempty"`
	// Output only. List of modalities that were processed in the request input.
	PromptTokensDetails []*ModalityTokenCount `json:"promptTokensDetails,omitempty"`
	// Output only. Number of tokens present in thoughts output.
	ThoughtsTokenCount int32 `json:"thoughtsTokenCount,omitempty"`
	// Output only. Number of tokens present in tool-use prompt(s).
	ToolUsePromptTokenCount int32 `json:"toolUsePromptTokenCount,omitempty"`
	// Output only. List of modalities that were processed for tool-use request inputs.
	ToolUsePromptTokensDetails []*ModalityTokenCount `json:"toolUsePromptTokensDetails,omitempty"`
	// Total token count for prompt, response candidates, and tool-use prompts (if present).
	TotalTokenCount int32 `json:"totalTokenCount,omitempty"`
	// Output only. Traffic type. This shows whether a request consumes Pay-As-You-Go or
	// Provisioned Throughput quota.
	TrafficType string `json:"trafficType,omitempty"`
}

// GenerateContentResponse represents response message for PredictionService.GenerateContent.
type GenerateContentResponse struct {
	// Response variations returned by the model.
	Candidates []*Candidate `json:"candidates,omitempty"`
	// Timestamp when the request is made to the server.
	CreateTime time.Time `json:"createTime,omitempty"`
	// Output only. The model version used to generate the response.
	ModelVersion string `json:"modelVersion,omitempty"`
	// Output only. Content filter results for a prompt sent in the request. Note: Sent
	// only in the first stream chunk. Only happens when no candidates were generated due
	// to content violations.
	PromptFeedback *GenerateContentResponsePromptFeedback `json:"promptFeedback,omitempty"`
	// Output only. response_id is used to identify each response. It is the encoding of
	// the event_id.
	ResponseID string `json:"responseId,omitempty"`
	// Usage metadata about the response(s).
	UsageMetadata *GenerateContentResponseUsageMetadata `json:"usageMetadata,omitempty"`
}

func (g *GenerateContentResponse) UnmarshalJSON(data []byte) error {
	type Alias GenerateContentResponse
	aux := &struct {
		CreateTime *time.Time `json:"createTime,omitempty"`
		*Alias
	}{
		Alias: (*Alias)(g),
	}

	if err := json.Unmarshal(data, &aux); err != nil {
		return err
	}

	if !reflect.ValueOf(aux.CreateTime).IsZero() {
		g.CreateTime = time.Time(*aux.CreateTime)
	}

	return nil
}

func (g *GenerateContentResponse) MarshalJSON() ([]byte, error) {
	type Alias GenerateContentResponse
	aux := &struct {
		CreateTime *time.Time `json:"createTime,omitempty"`
		*Alias
	}{
		Alias: (*Alias)(g),
	}

	if !reflect.ValueOf(g.CreateTime).IsZero() {
		aux.CreateTime = (*time.Time)(&g.CreateTime)
	}

	return json.Marshal(aux)
}

type GeminiGenerationError struct {
	Error *GeminiGenerationErrorStruct `json:"error,omitempty"`
}

type GeminiGenerationErrorStruct struct {
	Code    int                            `json:"code"`
	Message string                         `json:"message"`
	Status  string                         `json:"status"`
	Details []GeminiGenerationErrorDetails `json:"details"`
}

type GeminiGenerationErrorDetails struct {
	Type            string `json:"@type"`
	FieldViolations []struct {
		Description string `json:"description"`
	} `json:"fieldViolations"`
}

// ==================== MODEL TYPES ====================

type GeminiModel struct {
	Name                       string   `json:"name"`
	BaseModelID                string   `json:"baseModelId"`
	Version                    string   `json:"version"`
	DisplayName                string   `json:"displayName"`
	Description                string   `json:"description"`
	InputTokenLimit            int      `json:"inputTokenLimit"`
	OutputTokenLimit           int      `json:"outputTokenLimit"`
	SupportedGenerationMethods []string `json:"supportedGenerationMethods"`
	Thinking                   bool     `json:"thinking"`
	Temperature                float64  `json:"temperature"`
	MaxTemperature             float64  `json:"maxTemperature"`
	TopP                       float64  `json:"topP"`
	TopK                       int      `json:"topK"`
}

// GeminiListModelsResponse represents the response from Google Gemini's list models API.
type GeminiListModelsResponse struct {
	Models        []GeminiModel `json:"models"`
	NextPageToken string        `json:"nextPageToken"`
}

// ==================== BATCH API TYPES ====================
// Aligned with official documentation: https://ai.google.dev/gemini-api/docs/batch-api

// GeminiBatchCreateRequest represents the top-level request structure for creating a batch.
type GeminiBatchCreateRequest struct {
	Batch GeminiBatchConfig `json:"batch"`
}

// GeminiBatchConfig represents the batch configuration.
type GeminiBatchConfig struct {
	DisplayName string                 `json:"display_name,omitempty"`
	InputConfig GeminiBatchInputConfig `json:"input_config"`
}

// GeminiBatchInputConfig represents the input configuration for batch requests.
// Supports both inline requests and file-based input.
type GeminiBatchInputConfig struct {
	Requests *GeminiBatchRequestsWrapper `json:"requests,omitempty"`
	FileName string                      `json:"file_name,omitempty"`
}

// GeminiBatchRequestsWrapper wraps the array of batch request items.
type GeminiBatchRequestsWrapper struct {
	Requests []GeminiBatchRequestItem `json:"requests"`
}

// GeminiBatchRequestItem represents a single request in a batch with metadata.
type GeminiBatchRequestItem struct {
	Request  GeminiBatchGenerateContentRequest `json:"request"`
	Metadata *GeminiBatchMetadata              `json:"metadata,omitempty"`
}

// GeminiBatchGenerateContentRequest represents a GenerateContentRequest for batch.
type GeminiBatchGenerateContentRequest struct {
	Contents          []Content         `json:"contents"`
	GenerationConfig  *GenerationConfig `json:"generationConfig,omitempty"`
	SafetySettings    []SafetySetting   `json:"safetySettings,omitempty"`
	SystemInstruction *Content          `json:"systemInstruction,omitempty"`
}

// GeminiBatchStats represents the stats of a batch job.
type GeminiBatchStats struct {
	RequestCount           int `json:"requestCount"`
	PendingRequestCount    int `json:"pendingRequestCount"`
	SuccessfulRequestCount int `json:"successfulRequestCount"`
}

// MarshalJSON implements the json.Marshaler interface.
func (g *GeminiBatchStats) MarshalJSON() ([]byte, error) {
	return json.Marshal(struct {
		RequestCount           string `json:"requestCount"`
		PendingRequestCount    string `json:"pendingRequestCount"`
		SuccessfulRequestCount string `json:"successfulRequestCount"`
	}{
		RequestCount:           strconv.Itoa(g.RequestCount),
		PendingRequestCount:    strconv.Itoa(g.PendingRequestCount),
		SuccessfulRequestCount: strconv.Itoa(g.SuccessfulRequestCount),
	})
}

// UnmarshalJSON implements the json.Unmarshaler interface.
// Gemini API returns these counts as strings, so we need to parse them.
func (g *GeminiBatchStats) UnmarshalJSON(data []byte) error {
	var raw struct {
		RequestCount           string `json:"requestCount"`
		PendingRequestCount    string `json:"pendingRequestCount"`
		SuccessfulRequestCount string `json:"successfulRequestCount"`
	}
	if err := json.Unmarshal(data, &raw); err != nil {
		return err
	}
	if raw.RequestCount != "" {
		val, err := strconv.Atoi(raw.RequestCount)
		if err != nil {
			return err
		}
		g.RequestCount = val
	}
	if raw.PendingRequestCount != "" {
		val, err := strconv.Atoi(raw.PendingRequestCount)
		if err != nil {
			return err
		}
		g.PendingRequestCount = val
	}
	if raw.SuccessfulRequestCount != "" {
		val, err := strconv.Atoi(raw.SuccessfulRequestCount)
		if err != nil {
			return err
		}
		g.SuccessfulRequestCount = val
	}
	return nil
}

// GeminiBatchMetadataInputConfig represents the input config in batch job metadata.
// Note: This uses camelCase (fileName) unlike GeminiBatchInputConfig which uses snake_case (file_name).
type GeminiBatchMetadataInputConfig struct {
	FileName string `json:"fileName,omitempty"`
}

// GeminiBatchMetadataOutputConfig represents the output config in batch job metadata.
type GeminiBatchMetadataOutputConfig struct {
	ResponsesFile string `json:"responsesFile,omitempty"`
}

// GeminiBatchMetadata contains metadata for tracking batch requests.
type GeminiBatchMetadata struct {
	Key         string                           `json:"key"`
	Type        string                           `json:"@type"`
	Model       string                           `json:"model"`
	DisplayName string                           `json:"displayName"`
	InputConfig *GeminiBatchMetadataInputConfig  `json:"inputConfig,omitempty"`
	Output      *GeminiBatchMetadataOutputConfig `json:"output,omitempty"`
	CreateTime  string                           `json:"createTime"`
	EndTime     string                           `json:"endTime,omitempty"`
	UpdateTime  string                           `json:"updateTime"`
	BatchStats  *GeminiBatchStats                `json:"batchStats"`
	State       string                           `json:"state"`
	Name        string                           `json:"name"`
}

// GeminiBatchJobResponse represents the response from batch operations.
type GeminiBatchJobResponse struct {
	Name     string                `json:"name"` // e.g., "batches/xxx" or full resource name
	Dest     *GeminiBatchDest      `json:"dest,omitempty"`
	Error    *GeminiBatchErrorInfo `json:"error,omitempty"`
	Metadata *GeminiBatchMetadata  `json:"metadata,omitempty"`
	Done     bool                  `json:"done,omitempty"`
	Response *GeminiBatchOutput    `json:"response,omitempty"`
}

// GeminiBatchOutput represents the output of a successful batch job.
type GeminiBatchOutput struct {
	Type          string `json:"@type,omitempty"`
	ResponsesFile string `json:"responsesFile,omitempty"`
}

// GeminiBatchDest contains the destination/output of a batch job.
// For inline requests, results are in InlinedResponses.
// For file-based input, results are in a file referenced by FileName.
type GeminiBatchDest struct {
	InlinedResponses []GeminiInlinedResponse `json:"inlinedResponses,omitempty"`
	FileName         string                  `json:"fileName,omitempty"`
}

// GeminiInlinedResponse represents a single response in the batch output.
type GeminiInlinedResponse struct {
	Response *GenerateContentResponse `json:"response,omitempty"`
	Error    *GeminiBatchErrorInfo    `json:"error,omitempty"`
	Metadata *GeminiBatchMetadata     `json:"metadata,omitempty"`
}

// GeminiBatchErrorInfo represents error information.
type GeminiBatchErrorInfo struct {
	Code    int    `json:"code,omitempty"`
	Message string `json:"message,omitempty"`
	Status  string `json:"status,omitempty"`
}

// GeminiBatchFileResultLine represents a single line in the batch results JSONL file.
// Used when batch results are returned as a file rather than inline responses.
type GeminiBatchFileResultLine struct {
	Key      string                   `json:"key,omitempty"`
	Response *GenerateContentResponse `json:"response,omitempty"`
	Error    *GeminiBatchErrorInfo    `json:"error,omitempty"`
}

// GeminiBatchListResponse represents the response from listing batches.
type GeminiBatchListResponse struct {
	Operations    []GeminiBatchJobResponse `json:"operations,omitempty"`
	NextPageToken string                   `json:"nextPageToken,omitempty"`
}

// Gemini batch job states
const (
	GeminiBatchStateUnspecified = "BATCH_STATE_UNSPECIFIED"
	GeminiBatchStatePending     = "BATCH_STATE_PENDING"
	GeminiBatchStateRunning     = "BATCH_STATE_RUNNING"
	GeminiBatchStateSucceeded   = "BATCH_STATE_SUCCEEDED"
	GeminiBatchStateFailed      = "BATCH_STATE_FAILED"
	GeminiBatchStateCancelling  = "BATCH_STATE_CANCELLING"
	GeminiBatchStateCancelled   = "BATCH_STATE_CANCELLED"
	GeminiBatchStateExpired     = "BATCH_STATE_EXPIRED"
)

// ==================== FILE TYPES ====================

// GeminiFileUploadRequest represents the request for uploading a file.
type GeminiFileUploadRequest struct {
	File     []byte                `json:"-"`        // Raw file content (not serialized)
	Filename string                `json:"filename"` // Original filename
	Purpose  string                `json:"purpose"`  // Purpose of the file (e.g., "batch")
	Provider schemas.ModelProvider `json:"provider"`
}

// GeminiFileListRequest represents the request for listing files.
type GeminiFileListRequest struct {
	Limit int     `json:"limit,omitempty"`
	After *string `json:"after,omitempty"`
	Order *string `json:"order,omitempty"`
}

// GeminiFileRetrieveRequest request represents the request for retrieving a file.
type GeminiFileRetrieveRequest struct {
	FileID string `json:"file_id"`
}

// GeminiFileDeleteRequest request represents the request for deleting a file.
type GeminiFileDeleteRequest struct {
	FileID string `json:"file_id"`
}

// GeminiCountTokensResponse represents the response from Google Gemini's count tokens API.
type GeminiCountTokensResponse struct {
	// Response from models.countTokens
	// TotalTokens is the number of tokens that the Model tokenizes the prompt into.
	TotalTokens int32 `json:"totalTokens,omitempty"`
	// Number of tokens in the cached part of the prompt (the cached content).
	CachedContentTokenCount int32 `json:"cachedContentTokenCount,omitempty"`
	// Output only. List of modalities that were processed in the request input.
	PromptTokensDetails []*ModalityTokenCount `json:"promptTokensDetails,omitempty"`
	// Output only. List of modalities that were processed in the cached content.
	CacheTokensDetails []*ModalityTokenCount `json:"cacheTokensDetails,omitempty"`
}

var GeminiRequestSuffixPaths = []string{
	":streamGenerateContent",
	":generateContent",
	":countTokens",
	":embedContent",
	":batchEmbedContents",
	":predict",
}
