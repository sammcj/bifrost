# OpenAI Integration - Chat Completions Endpoints

chat-completions:
  post:
    operationId: openaiCreateChatCompletion
    summary: Create chat completion (OpenAI format)
    description: |
      Creates a chat completion using OpenAI-compatible format.
      Supports streaming via SSE.

      **Async inference:** Send `x-bf-async: true` to submit the request as a background job and receive a job ID immediately. Poll with `x-bf-async-id: <job-id>` to retrieve the result. When the job is still processing, the response will have an empty `choices` array. When completed, `choices` will contain the full result. See [Async Inference](/features/async-inference) for details.

      **Note:** This endpoint also works without the `/v1` prefix (e.g., `/openai/chat/completions`).
    tags:
      - OpenAI Integration
    parameters:
      - name: x-bf-async
        in: header
        required: false
        schema:
          type: string
          enum: ["true"]
        description: Set to `true` to submit this request as an async job. Returns immediately with a job ID. Not compatible with streaming.
      - name: x-bf-async-id
        in: header
        required: false
        schema:
          type: string
        description: Poll for results of a previously submitted async job by providing the job ID returned from the initial async request.
      - name: x-bf-async-job-result-ttl
        in: header
        required: false
        schema:
          type: integer
          default: 3600
        description: Override the default result TTL in seconds. Results expire after this duration from completion time.
    requestBody:
      required: true
      content:
        application/json:
          schema:
            $ref: '../../../schemas/integrations/openai/chat.yaml#/OpenAIChatRequest'
    responses:
      '200':
        description: Successful response
        content:
          application/json:
            schema:
              $ref: '../../../schemas/integrations/openai/chat.yaml#/OpenAIChatResponse'
          text/event-stream:
            schema:
              $ref: '../../../schemas/integrations/openai/chat.yaml#/OpenAIChatStreamResponse'
      '400':
        $ref: '../../../openapi.yaml#/components/responses/BadRequest'
      '500':
        $ref: '../../../openapi.yaml#/components/responses/InternalError'

# Azure deployment path
azure-chat-completions:
  post:
    operationId: azureCreateChatCompletion
    summary: Create chat completion (Azure OpenAI)
    description: |
      Creates a chat completion using Azure OpenAI deployment.
    tags:
      - OpenAI Integration
      - Azure Integration
    parameters:
      - name: deployment-id
        in: path
        required: true
        schema:
          type: string
        description: Azure deployment ID
      - name: api-version
        in: query
        schema:
          type: string
        description: Azure API version
    requestBody:
      required: true
      content:
        application/json:
          schema:
            $ref: '../../../schemas/integrations/openai/chat.yaml#/OpenAIChatRequest'
    responses:
      '200':
        description: Successful response
        content:
          application/json:
            schema:
              $ref: '../../../schemas/integrations/openai/chat.yaml#/OpenAIChatResponse'
          text/event-stream:
            schema:
              $ref: '../../../schemas/integrations/openai/chat.yaml#/OpenAIChatStreamResponse'
      '400':
        $ref: '../../../openapi.yaml#/components/responses/BadRequest'
      '500':
        $ref: '../../../openapi.yaml#/components/responses/InternalError'
