# Bifrost Integration Tests Configuration
# This file centralizes all configuration for AI integration clients and test settings

# Bifrost Gateway Configuration
# All integrations route through Bifrost as a proxy/gateway
bifrost:
  base_url: "${BIFROST_BASE_URL:-http://localhost:8080}"

  # Integration-specific endpoints (suffixes appended to base_url)
  endpoints:
    openai: "openai"
    anthropic: "anthropic"
    google: "genai"
    litellm: "litellm"
    langchain: "langchain"
    bedrock: "bedrock"

  # Full URLs constructed as: {base_url.rstrip('/')}/{endpoints[integration]}
  # Examples:
  # - OpenAI: http://localhost:8080/openai
  # - Anthropic: http://localhost:8080/anthropic
  # - Google: http://localhost:8080/genai
  # - LiteLLM: http://localhost:8080/litellm
  # - LangChain: http://localhost:8080/langchain

# API Configuration
api:
  timeout: 30 # seconds
  max_retries: 3
  retry_delay: 1 # seconds

# Provider model configurations
# Integrations (openai, anthropic, google, litellm, langchain) map to these providers
providers:
  openai:
    chat: "gpt-4o-mini"
    vision: "gpt-4o"
    tools: "gpt-4o-mini"
    speech: "tts-1"
    transcription: "whisper-1"
    embeddings: "text-embedding-3-small"
    streaming: "gpt-4o-mini"
    alternatives:
      - "gpt-4"
      - "gpt-4-turbo-preview"
      - "gpt-4o"
      - "gpt-3.5-turbo"
    
  anthropic:
    chat: "claude-sonnet-4-20250514"
    vision: "claude-3-7-sonnet-20250219"
    tools: "claude-sonnet-4-20250514"
    streaming: "claude-sonnet-4-20250514"
    thinking: "claude-sonnet-4-20250514"
    alternatives:
      - "claude-3-sonnet-20240229"
      - "claude-3-opus-20240229"
      - "claude-3-5-sonnet-20241022"
      - "claude-3-haiku-20240307"
    
  gemini:
    chat: "gemini-2.0-flash"
    vision: "gemini-2.0-flash"
    tools: "gemini-2.0-flash"
    speech: "gemini-2.5-flash-preview-tts"
    transcription: "gemini-2.5-flash"
    embeddings: "gemini-embedding-001"
    streaming: "gemini-2.0-flash"
    alternatives:
      - "gemini-1.5-pro"
      - "gemini-1.5-flash"
      - "gemini-1.0-pro"
      - "gemini-2.0-flash-001"
    
  bedrock:
    chat: "anthropic.claude-3-5-sonnet-20240620-v1:0"
    vision: "anthropic.claude-3-5-sonnet-20240620-v1:0"
    tools: "anthropic.claude-3-5-sonnet-20240620-v1:0"
    streaming: "anthropic.claude-3-5-sonnet-20240620-v1:0"
    thinking: "anthropic.claude-3-5-sonnet-20240620-v1:0"
    text_completion: "mistral.mistral-7b-instruct-v0:2"
    embeddings: "cohere.embed-v4:0"
    alternatives:
      - "anthropic.claude-3-opus-20240229-v1:0"
    
  cohere:
    chat: "command-a-03-2025"
    vision: "command-a-vision-07-2025"
    tools: "command-a-03-2025"
    embeddings: "embed-v4.0"
    streaming: "command-a-03-2025"
    alternatives:
      - "command-r-plus"

# Provider availability configuration
# Maps provider names to their API key environment variables
provider_api_keys:
  openai: "OPENAI_API_KEY"
  anthropic: "ANTHROPIC_API_KEY"
  gemini: "GEMINI_API_KEY"
  bedrock: "BEDROCK_API_KEY"
  cohere: "COHERE_API_KEY"

# Provider test scenarios - which tests each provider supports
provider_scenarios:
  openai:
    simple_chat: true
    multi_turn_conversation: true
    streaming: true
    tool_calls: true
    multiple_tool_calls: true
    end2end_tool_calling: true
    automatic_function_calling: true
    image_url: true
    image_base64: true
    multiple_images: true
    speech_synthesis: true
    speech_synthesis_streaming: true
    transcription: true
    transcription_streaming: true
    embeddings: true
    thinking: false
    list_models: true
    responses: true
    responses_image: true
    text_completion: false
    
  anthropic:
    simple_chat: true
    multi_turn_conversation: true
    streaming: true
    tool_calls: true
    multiple_tool_calls: true
    end2end_tool_calling: true
    automatic_function_calling: true
    image_url: true
    image_base64: true
    multiple_images: true
    speech_synthesis: false
    speech_synthesis_streaming: false
    transcription: false
    transcription_streaming: false
    embeddings: false
    thinking: true
    list_models: true
    responses: true
    responses_image: true
    text_completion: false
    
  gemini:
    simple_chat: true
    multi_turn_conversation: true
    streaming: true
    tool_calls: true
    multiple_tool_calls: true
    end2end_tool_calling: true
    automatic_function_calling: true
    image_url: false  # Gemini requires base64 or file upload
    image_base64: true
    multiple_images: false
    speech_synthesis: true
    speech_synthesis_streaming: true
    transcription: true
    transcription_streaming: true
    embeddings: true
    thinking: false
    list_models: true
    responses: true
    responses_image: true
    text_completion: false
    
  bedrock:
    simple_chat: true
    multi_turn_conversation: true
    streaming: true
    tool_calls: true
    multiple_tool_calls: true
    end2end_tool_calling: true
    automatic_function_calling: true
    image_url: false
    image_base64: true
    multiple_images: false
    speech_synthesis: false
    speech_synthesis_streaming: false
    transcription: false
    transcription_streaming: false
    embeddings: true
    thinking: true
    list_models: true
    responses: true
    responses_image: true
    text_completion: false
    
  cohere:
    simple_chat: true
    multi_turn_conversation: true
    streaming: true
    tool_calls: true
    multiple_tool_calls: true
    end2end_tool_calling: true
    automatic_function_calling: false
    image_url: true
    image_base64: true
    multiple_images: true
    speech_synthesis: false
    speech_synthesis_streaming: false
    transcription: false
    transcription_streaming: false
    embeddings: true
    thinking: false
    list_models: false
    responses: true
    responses_image: true
    text_completion: false

# Scenario to capability mapping
# Maps test scenario names to their corresponding capability types
scenario_capabilities:
  simple_chat: "chat"
  multi_turn_conversation: "chat"
  responses: "chat"
  responses_image: "vision"
  text_completion: "chat"
  streaming: "streaming"
  tool_calls: "tools"
  multiple_tool_calls: "tools"
  end2end_tool_calling: "tools"
  automatic_function_calling: "tools"
  image_url: "vision"
  image_base64: "vision"
  multiple_images: "vision"
  speech_synthesis: "speech"
  speech_synthesis_streaming: "speech"
  transcription: "transcription"
  transcription_streaming: "transcription"
  embeddings: "embeddings"
  thinking: "thinking"
  list_models: "chat"

# Model capabilities matrix
model_capabilities:
  # OpenAI Models
  "gpt-3.5-turbo":
    chat: true
    tools: true
    vision: false
    streaming: true
    max_tokens: 4096
    context_window: 4096

  "gpt-4":
    chat: true
    tools: true
    vision: false
    streaming: true
    max_tokens: 8192
    context_window: 8192

  "gpt-4o":
    chat: true
    tools: true
    vision: true
    streaming: true
    max_tokens: 4096
    context_window: 128000

  "gpt-4o-mini":
    chat: true
    tools: true
    vision: true
    streaming: true
    speech: false
    transcription: false
    max_tokens: 4096
    context_window: 128000

  # OpenAI Speech Models
  "tts-1":
    chat: false
    tools: false
    vision: false
    streaming: false
    speech: true
    transcription: false
    max_tokens: null
    context_window: null

  "tts-1-hd":
    chat: false
    tools: false
    vision: false
    streaming: false
    speech: true
    transcription: false
    max_tokens: null
    context_window: null

  # OpenAI Transcription Models
  "whisper-1":
    chat: false
    tools: false
    vision: false
    streaming: false
    speech: false
    transcription: true
    embeddings: false
    max_tokens: null
    context_window: null

  # OpenAI Embedding Models
  "text-embedding-3-small":
    chat: false
    tools: false
    vision: false
    streaming: false
    speech: false
    transcription: false
    embeddings: true
    max_tokens: null
    context_window: 8191
    dimensions: 1536

  "text-embedding-3-large":
    chat: false
    tools: false
    vision: false
    streaming: false
    speech: false
    transcription: false
    embeddings: true
    max_tokens: null
    context_window: 8191
    dimensions: 3072

  "text-embedding-ada-002":
    chat: false
    tools: false
    vision: false
    streaming: false
    speech: false
    transcription: false
    embeddings: true
    max_tokens: null
    context_window: 8191
    dimensions: 1536

  # Anthropic Models
  "claude-3-haiku-20240307":
    chat: true
    tools: true
    vision: true
    streaming: true
    max_tokens: 4096
    context_window: 200000

  "claude-3-sonnet-20240229":
    chat: true
    tools: true
    vision: true
    streaming: true
    max_tokens: 4096
    context_window: 200000

  "claude-3-opus-20240229":
    chat: true
    tools: true
    vision: true
    streaming: true
    max_tokens: 4096
    context_window: 200000

  # Google Models
  "gemini-pro":
    chat: true
    tools: true
    vision: false
    streaming: true
    max_tokens: 8192
    context_window: 32768

  "gemini-2.0-flash-001":
    chat: true
    tools: true
    vision: true
    streaming: true
    max_tokens: 8192
    context_window: 32768

  "gemini-1.5-pro":
    chat: true
    tools: true
    vision: true
    streaming: true
    max_tokens: 8192
    context_window: 1000000

  # Gemini Transcription Models
  "gemini-2.5-flash":
    chat: true
    tools: true
    vision: true
    streaming: true
    speech: false
    transcription: true
    embeddings: false
    max_tokens: 8192
    context_window: 1000000
    audio_max_duration: 34200  # 9.5 hours in seconds

  "gemini-2.5-pro":
    chat: true
    tools: true
    vision: true
    streaming: true
    speech: false
    transcription: true
    embeddings: false
    max_tokens: 8192
    context_window: 2000000
    audio_max_duration: 34200  # 9.5 hours in seconds

  # Gemini TTS Models
  "gemini-2.5-flash-preview-tts":
    chat: false
    tools: false
    vision: false
    streaming: false
    speech: true
    transcription: false
    embeddings: false
    max_tokens: 32000  # 32k token context window for TTS
    context_window: 32000
    audio_format: "pcm"
    sample_rate: 24000
    channels: 1

  "gemini-2.5-pro-preview-tts":
    chat: false
    tools: false
    vision: false
    streaming: false
    speech: true
    transcription: false
    embeddings: false
    max_tokens: 32000  # 32k token context window for TTS
    context_window: 32000
    audio_format: "pcm"
    sample_rate: 24000
    channels: 1

  # Mistral Models
  "mistral-7b-instruct":
    chat: true
    tools: false
    vision: false
    streaming: true
    max_tokens: 4096
    context_window: 32768

  "mistral-8x7b-instruct":
    chat: true
    tools: true
    vision: false
    streaming: true
    max_tokens: 4096
    context_window: 32768

# Test configuration
test_settings:
  # Maximum tokens for test responses
  max_tokens:
    chat: 100
    vision: 200
    tools: 100
    complex: 300
    speech: null  # Speech doesn't use token limits
    transcription: null  # Transcription doesn't use token limits
    embeddings: null  # Embeddings don't use token limits (text is the input)

  # Timeout settings for tests
  timeouts:
    simple: 30 # seconds
    complex: 60 # seconds

  # Retry settings for flaky tests
  retries:
    max_attempts: 3
    delay: 2 # seconds

# Integration-specific settings
integration_settings:
  openai:
    organization: "${OPENAI_ORG_ID:-}"
    project: "${OPENAI_PROJECT_ID:-}"

  anthropic:
    version: "2023-06-01"

  google:
    project_id: "${GOOGLE_PROJECT_ID:-}"
    location: "${GOOGLE_LOCATION:-us-central1}"

  litellm:
    drop_params: true
    debug: false

  langchain:
    debug: false
    streaming: true

  bedrock:
    region: "${AWS_REGION:-us-west-2}"

# Environment-specific overrides
environments:
  development:
    api:
      timeout: 60
      max_retries: 5
    test_settings:
      timeouts:
        simple: 60
        complex: 120

  production:
    api:
      timeout: 15
      max_retries: 2
    test_settings:
      timeouts:
        simple: 20
        complex: 40

# Logging configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "tests.log"
