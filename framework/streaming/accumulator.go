// Package streaming provides functionality for accumulating streaming chunks and other chunk-related workflows
package streaming

import (
	"fmt"
	"sync"
	"time"

	schemas "github.com/maximhq/bifrost/core/schemas"
	"github.com/maximhq/bifrost/framework/modelcatalog"
)

// getAccumulatorID extracts the ID for accumulator lookup from context.
// Returns the value of BifrostContextKeyAccumulatorID.
func getAccumulatorID(ctx *schemas.BifrostContext) (string, bool) {
	if id, ok := (*ctx).Value(schemas.BifrostContextKeyAccumulatorID).(string); ok && id != "" {
		return id, true
	}
	return "", false
}

// Accumulator manages accumulation of streaming chunks
type Accumulator struct {
	logger schemas.Logger

	streamAccumulators sync.Map // Track accumulators by request ID (atomic)

	chatStreamChunkPool          sync.Pool // Pool for reusing StreamChunk structs
	responsesStreamChunkPool     sync.Pool // Pool for reusing ResponsesStreamChunk structs
	audioStreamChunkPool         sync.Pool // Pool for reusing AudioStreamChunk structs
	transcriptionStreamChunkPool sync.Pool // Pool for reusing TranscriptionStreamChunk structs

	pricingManager *modelcatalog.ModelCatalog

	stopCleanup   chan struct{}
	cleanupWg     sync.WaitGroup
	ttl           time.Duration
	cleanupTicker *time.Ticker
}

// getChatStreamChunk gets a chat stream chunk from the pool
func (a *Accumulator) getChatStreamChunk() *ChatStreamChunk {
	return a.chatStreamChunkPool.Get().(*ChatStreamChunk)
}

// putChatStreamChunk returns a chat stream chunk to the pool
func (a *Accumulator) putChatStreamChunk(chunk *ChatStreamChunk) {
	chunk.Timestamp = time.Time{}
	chunk.Delta = nil
	chunk.Cost = nil
	chunk.SemanticCacheDebug = nil
	chunk.ErrorDetails = nil
	chunk.FinishReason = nil
	chunk.TokenUsage = nil
	chunk.RawResponse = nil
	a.chatStreamChunkPool.Put(chunk)
}

// GetAudioStreamChunk gets an audio stream chunk from the pool
func (a *Accumulator) getAudioStreamChunk() *AudioStreamChunk {
	return a.audioStreamChunkPool.Get().(*AudioStreamChunk)
}

// PutAudioStreamChunk returns an audio stream chunk to the pool
func (a *Accumulator) putAudioStreamChunk(chunk *AudioStreamChunk) {
	chunk.Timestamp = time.Time{}
	chunk.Delta = nil
	chunk.Cost = nil
	chunk.SemanticCacheDebug = nil
	chunk.ErrorDetails = nil
	chunk.FinishReason = nil
	chunk.TokenUsage = nil
	chunk.RawResponse = nil
	a.audioStreamChunkPool.Put(chunk)
}

// getTranscriptionStreamChunk gets a transcription stream chunk from the pool
func (a *Accumulator) getTranscriptionStreamChunk() *TranscriptionStreamChunk {
	return a.transcriptionStreamChunkPool.Get().(*TranscriptionStreamChunk)
}

// putTranscriptionStreamChunk returns a transcription stream chunk to the pool
func (a *Accumulator) putTranscriptionStreamChunk(chunk *TranscriptionStreamChunk) {
	chunk.Timestamp = time.Time{}
	chunk.Delta = nil
	chunk.Cost = nil
	chunk.SemanticCacheDebug = nil
	chunk.ErrorDetails = nil
	chunk.FinishReason = nil
	chunk.TokenUsage = nil
	chunk.RawResponse = nil
	a.transcriptionStreamChunkPool.Put(chunk)
}

// getResponsesStreamChunk gets a responses stream chunk from the pool
func (a *Accumulator) getResponsesStreamChunk() *ResponsesStreamChunk {
	return a.responsesStreamChunkPool.Get().(*ResponsesStreamChunk)
}

// putResponsesStreamChunk returns a responses stream chunk to the pool
func (a *Accumulator) putResponsesStreamChunk(chunk *ResponsesStreamChunk) {
	chunk.Timestamp = time.Time{}
	chunk.StreamResponse = nil
	chunk.Cost = nil
	chunk.SemanticCacheDebug = nil
	chunk.ErrorDetails = nil
	chunk.FinishReason = nil
	chunk.TokenUsage = nil
	chunk.RawResponse = nil
	a.responsesStreamChunkPool.Put(chunk)
}

// createStreamAccumulator creates a new stream accumulator for a request
// StartTimestamp is set to current time if not provided via CreateStreamAccumulator
func (a *Accumulator) createStreamAccumulator(requestID string) *StreamAccumulator {
	now := time.Now()
	sc := &StreamAccumulator{
		RequestID:                  requestID,
		ChatStreamChunks:           make([]*ChatStreamChunk, 0),
		ResponsesStreamChunks:      make([]*ResponsesStreamChunk, 0),
		TranscriptionStreamChunks:  make([]*TranscriptionStreamChunk, 0),
		AudioStreamChunks:          make([]*AudioStreamChunk, 0),
		ChatChunksSeen:             make(map[int]struct{}),
		ResponsesChunksSeen:        make(map[int]struct{}),
		TranscriptionChunksSeen:    make(map[int]struct{}),
		AudioChunksSeen:            make(map[int]struct{}),
		MaxChatChunkIndex:          -1,
		MaxResponsesChunkIndex:     -1,
		MaxTranscriptionChunkIndex: -1,
		MaxAudioChunkIndex:         -1,
		IsComplete:                 false,
		Timestamp:                  now,
		StartTimestamp:             now, // Set default StartTimestamp for proper TTFT/latency calculation
	}
	a.streamAccumulators.Store(requestID, sc)
	return sc
}

// GetOrCreateStreamAccumulator gets or creates a stream accumulator for a request
func (a *Accumulator) getOrCreateStreamAccumulator(requestID string) *StreamAccumulator {
	if accumulator, exists := a.streamAccumulators.Load(requestID); exists {
		return accumulator.(*StreamAccumulator)
	}
	// Create new accumulator if it doesn't exist
	return a.createStreamAccumulator(requestID)
}

// AddStreamChunk adds a chunk to the stream accumulator
func (a *Accumulator) addChatStreamChunk(requestID string, chunk *ChatStreamChunk, isFinalChunk bool) error {
	accumulator := a.getOrCreateStreamAccumulator(requestID)
	// Lock the accumulator
	accumulator.mu.Lock()
	defer accumulator.mu.Unlock()
	if accumulator.StartTimestamp.IsZero() {
		accumulator.StartTimestamp = chunk.Timestamp
	}
	// Track first chunk timestamp for TTFT calculation
	if accumulator.FirstChunkTimestamp.IsZero() {
		accumulator.FirstChunkTimestamp = chunk.Timestamp
	}
	// De-dup check - only add if not seen (handles out-of-order arrival and multiple plugins)
	if _, seen := accumulator.ChatChunksSeen[chunk.ChunkIndex]; !seen {
		accumulator.ChatChunksSeen[chunk.ChunkIndex] = struct{}{}
		accumulator.ChatStreamChunks = append(accumulator.ChatStreamChunks, chunk)
		// Track max index for metadata extraction
		if chunk.ChunkIndex > accumulator.MaxChatChunkIndex {
			accumulator.MaxChatChunkIndex = chunk.ChunkIndex
		}
	}
	// Check if this is the final chunk
	// Set FinalTimestamp when either FinishReason is present or token usage exists
	// This handles both normal completion chunks and usage-only last chunks
	if isFinalChunk {
		accumulator.FinalTimestamp = chunk.Timestamp
	}
	return nil
}

// AddTranscriptionStreamChunk adds a transcription stream chunk to the stream accumulator
func (a *Accumulator) addTranscriptionStreamChunk(requestID string, chunk *TranscriptionStreamChunk, isFinalChunk bool) error {
	accumulator := a.getOrCreateStreamAccumulator(requestID)
	// Lock the accumulator
	accumulator.mu.Lock()
	defer accumulator.mu.Unlock()
	if accumulator.StartTimestamp.IsZero() {
		accumulator.StartTimestamp = chunk.Timestamp
	}
	// Track first chunk timestamp for TTFT calculation
	if accumulator.FirstChunkTimestamp.IsZero() {
		accumulator.FirstChunkTimestamp = chunk.Timestamp
	}
	if _, seen := accumulator.TranscriptionChunksSeen[chunk.ChunkIndex]; !seen {
		accumulator.TranscriptionChunksSeen[chunk.ChunkIndex] = struct{}{}
		accumulator.TranscriptionStreamChunks = append(accumulator.TranscriptionStreamChunks, chunk)
		// Track max index for metadata extraction
		if chunk.ChunkIndex > accumulator.MaxTranscriptionChunkIndex {
			accumulator.MaxTranscriptionChunkIndex = chunk.ChunkIndex
		}
	}
	// Check if this is the final chunk
	// Set FinalTimestamp when either FinishReason is present or token usage exists
	// This handles both normal completion chunks and usage-only last chunks
	if isFinalChunk {
		accumulator.FinalTimestamp = chunk.Timestamp
	}
	return nil
}

// AddAudioStreamChunk adds an audio stream chunk to the stream accumulator
func (a *Accumulator) addAudioStreamChunk(requestID string, chunk *AudioStreamChunk, isFinalChunk bool) error {
	accumulator := a.getOrCreateStreamAccumulator(requestID)
	// Lock the accumulator
	accumulator.mu.Lock()
	defer accumulator.mu.Unlock()
	if accumulator.StartTimestamp.IsZero() {
		accumulator.StartTimestamp = chunk.Timestamp
	}
	// Track first chunk timestamp for TTFT calculation
	if accumulator.FirstChunkTimestamp.IsZero() {
		accumulator.FirstChunkTimestamp = chunk.Timestamp
	}
	if _, seen := accumulator.AudioChunksSeen[chunk.ChunkIndex]; !seen {
		accumulator.AudioChunksSeen[chunk.ChunkIndex] = struct{}{}
		accumulator.AudioStreamChunks = append(accumulator.AudioStreamChunks, chunk)
		// Track max index for metadata extraction
		if chunk.ChunkIndex > accumulator.MaxAudioChunkIndex {
			accumulator.MaxAudioChunkIndex = chunk.ChunkIndex
		}
	}
	// Check if this is the final chunk
	// Set FinalTimestamp when either FinishReason is present or token usage exists
	// This handles both normal completion chunks and usage-only last chunks
	if isFinalChunk {
		accumulator.FinalTimestamp = chunk.Timestamp
	}
	return nil
}

// addResponsesStreamChunk adds a responses stream chunk to the stream accumulator
func (a *Accumulator) addResponsesStreamChunk(requestID string, chunk *ResponsesStreamChunk, isFinalChunk bool) error {
	accumulator := a.getOrCreateStreamAccumulator(requestID)
	// Lock the accumulator
	accumulator.mu.Lock()
	defer accumulator.mu.Unlock()
	if accumulator.StartTimestamp.IsZero() {
		accumulator.StartTimestamp = chunk.Timestamp
	}
	// Track first chunk timestamp for TTFT calculation
	if accumulator.FirstChunkTimestamp.IsZero() {
		accumulator.FirstChunkTimestamp = chunk.Timestamp
	}
	if _, seen := accumulator.ResponsesChunksSeen[chunk.ChunkIndex]; !seen {
		accumulator.ResponsesChunksSeen[chunk.ChunkIndex] = struct{}{}
		accumulator.ResponsesStreamChunks = append(accumulator.ResponsesStreamChunks, chunk)
		// Track max index for metadata extraction
		if chunk.ChunkIndex > accumulator.MaxResponsesChunkIndex {
			accumulator.MaxResponsesChunkIndex = chunk.ChunkIndex
		}
	}
	// Check if this is the final chunk
	// Set FinalTimestamp when either FinishReason is present or token usage exists
	// This handles both normal completion chunks and usage-only last chunks
	if isFinalChunk {
		accumulator.FinalTimestamp = chunk.Timestamp
	}
	return nil
}

// cleanupStreamAccumulator removes the stream accumulator for a request.
// IMPORTANT: Caller must hold accumulator.mu lock before calling this function
// to prevent races when returning chunks to pools.
func (a *Accumulator) cleanupStreamAccumulator(requestID string) {
	if accumulator, exists := a.streamAccumulators.Load(requestID); exists {
		acc := accumulator.(*StreamAccumulator)

		// Return all chunks to the pool before deleting
		for _, chunk := range acc.ChatStreamChunks {
			a.putChatStreamChunk(chunk)
		}
		for _, chunk := range acc.ResponsesStreamChunks {
			a.putResponsesStreamChunk(chunk)
		}
		for _, chunk := range acc.AudioStreamChunks {
			a.putAudioStreamChunk(chunk)
		}
		for _, chunk := range acc.TranscriptionStreamChunks {
			a.putTranscriptionStreamChunk(chunk)
		}
		a.streamAccumulators.Delete(requestID)
	}
}

// accumulateToolCallsInMessage efficiently accumulates tool calls in a message
func (a *Accumulator) accumulateToolCallsInMessage(message *schemas.ChatMessage, deltaToolCalls []schemas.ChatAssistantMessageToolCall) {
	if message == nil {
		return
	}
	if message.ChatAssistantMessage == nil {
		message.ChatAssistantMessage = &schemas.ChatAssistantMessage{}
	}
	existingToolCalls := message.ChatAssistantMessage.ToolCalls
	for _, deltaToolCall := range deltaToolCalls {
		var toolCallToModify *schemas.ChatAssistantMessageToolCall
		// Checking if delta tool name is present,
		// If present, then it could be different tool call
		if deltaToolCall.Function.Name != nil {
			// Creating a new tool call
			// Only set arguments if they're not empty or just empty braces
			args := deltaToolCall.Function.Arguments
			if args == "{}" {
				args = "" // Reset empty braces to empty string to avoid duplication
			}
			toolCallToModify = &schemas.ChatAssistantMessageToolCall{
				Index: uint16(len(existingToolCalls)),
				ID:    deltaToolCall.ID,
				Function: schemas.ChatAssistantMessageToolCallFunction{
					Name:      deltaToolCall.Function.Name,
					Arguments: args,
				},
			}
			existingToolCalls = append(existingToolCalls, *toolCallToModify)
		} else {
			// Ensure there's at least one tool call to modify
			if len(existingToolCalls) == 0 {
				a.logger.Warn("received tool call delta without name, but no existing tool calls to append to")
				continue
			}
			// Otherwise we will modify the last tool call
			toolCallToModify = &existingToolCalls[len(existingToolCalls)-1]
			toolCallToModify.Function.Arguments += deltaToolCall.Function.Arguments
		}
	}
	message.ChatAssistantMessage.ToolCalls = existingToolCalls
}

// appendContentToMessage efficiently appends content to a message
func (a *Accumulator) appendContentToMessage(message *schemas.ChatMessage, newContent string) {
	if message == nil {
		return
	}
	if message.Content != nil && message.Content.ContentStr != nil {
		// Append to existing string content
		*message.Content.ContentStr += newContent
	} else if message.Content != nil && message.Content.ContentBlocks != nil {
		// Find the last text block and append, or create new one
		blocks := message.Content.ContentBlocks
		if len(blocks) > 0 && blocks[len(blocks)-1].Type == schemas.ChatContentBlockTypeText && blocks[len(blocks)-1].Text != nil {
			// Append to last text block
			*blocks[len(blocks)-1].Text += newContent
		} else {
			// Create new text block
			blocks = append(blocks, schemas.ChatContentBlock{
				Type: schemas.ChatContentBlockTypeText,
				Text: &newContent,
			})
			message.Content.ContentBlocks = blocks
		}
	} else {
		if message.Content == nil {
			message.Content = &schemas.ChatMessageContent{}
		}
		// Initialize with string content
		message.Content.ContentStr = &newContent
	}
}

// ProcessStreamingResponse processes a streaming response
// It handles chat, audio, and responses streaming responses
func (a *Accumulator) ProcessStreamingResponse(ctx *schemas.BifrostContext, result *schemas.BifrostResponse, bifrostErr *schemas.BifrostError) (*ProcessedStreamResponse, error) {
	// Check if this is a streaming response
	if result == nil {
		return nil, fmt.Errorf("result is nil")
	}
	extraFields := result.GetExtraFields()
	requestType := extraFields.RequestType
	isAudioStreaming := requestType == schemas.SpeechStreamRequest || requestType == schemas.TranscriptionStreamRequest
	isChatStreaming := requestType == schemas.ChatCompletionStreamRequest || requestType == schemas.TextCompletionStreamRequest
	isResponsesStreaming := requestType == schemas.ResponsesStreamRequest

	if isChatStreaming {
		// Handle text-based streaming with ordered accumulation
		return a.processChatStreamingResponse(ctx, result, bifrostErr)
	} else if isAudioStreaming {
		// Handle speech/transcription streaming with original flow
		if requestType == schemas.TranscriptionStreamRequest {
			return a.processTranscriptionStreamingResponse(ctx, result, bifrostErr)
		}
		if requestType == schemas.SpeechStreamRequest {
			return a.processAudioStreamingResponse(ctx, result, bifrostErr)
		}
	} else if isResponsesStreaming {
		// Handle responses streaming with responses accumulation
		return a.processResponsesStreamingResponse(ctx, result, bifrostErr)
	}
	return nil, fmt.Errorf("request type missing/invalid for accumulator: %s", requestType)
}

// Cleanup cleans up the accumulator
func (a *Accumulator) Cleanup() {
	// Clean up all stream accumulators
	a.streamAccumulators.Range(func(key, value interface{}) bool {
		accumulator := value.(*StreamAccumulator)

		// Lock before accessing chunk slices
		accumulator.mu.Lock()
		for _, chunk := range accumulator.ChatStreamChunks {
			a.chatStreamChunkPool.Put(chunk)
		}
		for _, chunk := range accumulator.ResponsesStreamChunks {
			a.responsesStreamChunkPool.Put(chunk)
		}
		for _, chunk := range accumulator.TranscriptionStreamChunks {
			a.transcriptionStreamChunkPool.Put(chunk)
		}
		for _, chunk := range accumulator.AudioStreamChunks {
			a.audioStreamChunkPool.Put(chunk)
		}
		accumulator.mu.Unlock()

		a.streamAccumulators.Delete(key)
		return true
	})
	close(a.stopCleanup)
	a.cleanupTicker.Stop()
	a.cleanupWg.Wait()
}

// CreateStreamAccumulator creates a new stream accumulator for a request
func (a *Accumulator) CreateStreamAccumulator(requestID string, startTimestamp time.Time) *StreamAccumulator {
	sc := a.getOrCreateStreamAccumulator(requestID)
	// Lock before writing to StartTimestamp
	sc.mu.Lock()
	sc.StartTimestamp = startTimestamp
	sc.mu.Unlock()
	return sc
}

// CleanupStreamAccumulator cleans up the stream accumulator for a request
func (a *Accumulator) CleanupStreamAccumulator(requestID string) error {
	acc, exists := a.streamAccumulators.Load(requestID)
	if !exists {
		return fmt.Errorf("accumulator not found for request ID: %s", requestID)
	}
	if accumulator, ok := acc.(*StreamAccumulator); ok {
		accumulator.mu.Lock()
		defer accumulator.mu.Unlock()
		a.cleanupStreamAccumulator(requestID)
	}
	return nil
}

// cleanupOldAccumulators removes old accumulators
func (a *Accumulator) cleanupOldAccumulators() {
	count := 0
	a.streamAccumulators.Range(func(key, value interface{}) bool {
		accumulator := value.(*StreamAccumulator)
		accumulator.mu.Lock()
		defer accumulator.mu.Unlock()
		if accumulator.Timestamp.Before(time.Now().Add(-a.ttl)) {
			a.cleanupStreamAccumulator(key.(string))
		}
		count++
		return true
	})

	a.logger.Debug("[streaming] cleanup old accumulators done. current size: %d entries", count)
}

// startCleanup runs in a background goroutine to periodically remove expired entries
func (a *Accumulator) startAccumulatorMapCleanup() {
	defer a.cleanupWg.Done()

	for {
		select {
		case <-a.cleanupTicker.C:
			a.cleanupOldAccumulators()
		case <-a.stopCleanup:
			return
		}
	}
}

// NewAccumulator creates a new accumulator
func NewAccumulator(pricingManager *modelcatalog.ModelCatalog, logger schemas.Logger) *Accumulator {
	a := &Accumulator{
		streamAccumulators: sync.Map{},
		chatStreamChunkPool: sync.Pool{
			New: func() any {
				return &ChatStreamChunk{}
			},
		},
		responsesStreamChunkPool: sync.Pool{
			New: func() any {
				return &ResponsesStreamChunk{}
			},
		},
		audioStreamChunkPool: sync.Pool{
			New: func() any {
				return &AudioStreamChunk{}
			},
		},
		transcriptionStreamChunkPool: sync.Pool{
			New: func() any {
				return &TranscriptionStreamChunk{}
			},
		},
		pricingManager: pricingManager,
		logger:         logger,
		ttl:            30 * time.Minute,
		cleanupTicker:  time.NewTicker(1 * time.Minute),
		cleanupWg:      sync.WaitGroup{},
		stopCleanup:    make(chan struct{}),
	}
	a.cleanupWg.Add(1)
	// Prewarm the pools for better performance at startup
	for range 1000 {
		a.chatStreamChunkPool.Put(&ChatStreamChunk{})
		a.responsesStreamChunkPool.Put(&ResponsesStreamChunk{})
		a.audioStreamChunkPool.Put(&AudioStreamChunk{})
		a.transcriptionStreamChunkPool.Put(&TranscriptionStreamChunk{})
	}
	go a.startAccumulatorMapCleanup()
	return a
}
